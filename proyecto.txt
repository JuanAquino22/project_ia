Comparativa de...
LLMs Prompting o Agente conversacional sin RAG vs.
Agente conversacional RAG
Instrucciones de actividad
Preliminares
Si la entrega es grupal, se aceptan hasta 3 integrantes por grupo.
En el documento de entrega se deben incluir los integrantes y cada uno debe realizar la entrega de la tarea en la sección habilitada de esta plataforma.
El documento de entrega, puede ser un jupyter notebook o un link a un notebook de google colab:
Todo el código necesario para los sistemas/agentes conversacionales deben estar incluidos dentro de los notebook. Hay dos opciones:
Se puede embeber todo el código y pasos necesarios para su ejecución dentro de las celdas del notebook mismo (como se hizo en clase) e ir incluyendo las celdas que se crean necesarias.
Se puede referenciar dentro de ese colab a un repo de github.com con todo el código y un README.md que instruya los pasos para su ejecución. 
El notebook de plantilla para la entrega es el siguiente: https://colab.research.google.com/github/mmaguero/diploma_fpuna_nlp_ia/blob/master/2025/final_project_guide.ipynb
Un ejemplo de repo en github.com puede ser el siguiente (sin olvidar el README.md con las instrucciones de instalación y ejecución): https://github.com/mmaguero/diploma_fpuna_nlp_ia/tree/master/2025/rag_chatbot
Se deben completar las secciones de la plantilla con los experimentos realizados, incluyendo código, pantallazos, plots, imágenes, prompts, etc. y todo lo que se crea necesario dentro de ella.
Matriz de calificación: Se adjunta la matriz con la que se calificará el trabajo, deben tenerla en cuenta a la hora de elaborar el mismo. Adjunta a la tarea.
A. Selección de Documentos para Indexación
Dado el interés en el Guaraní (o el Jopará, que es la mezcla de guaraní y español), se puede encontrar y utilizar documentación lingüística o corpus paralelos como base de conocimiento para el sistema RAG.

Propósito: La generación de texto sintético en guaraní a partir de reglas gramaticales requiere que el LLM recupere contextos normativos o patrones de uso lingüístico.
AmericasNLP: Se puede utilizar este dataset para evaluar el chatbot: https://github.com/AmericasNLP/americasnlp2025/tree/main/ST2_EducationalMaterials/data (sería el set de guaraní) [https://turing.iimas.unam.mx/americasnlp/2025_st_2.html].
Objetivo: En esta tarea, se cuenta con un conjunto de datos con oraciones base (campo Source). Este conjunto también contendrá una indicación del cambio (campo Change) que se espera que el chatbot sea capaz de realizar en cada oración base (campo Target). Los sistemas transformarán la oración base (campo Source) en una oración objetivo (campo Target) según el cambio (campo Change) indicado.
Source -> Change -> ¿?, dónde ¿? es lo que debemos generar y evaluar.
Ejemplo (https://github.com/AmericasNLP/americasnlp2025/blob/main/ST2_EducationalMaterials/data/guarani-dev.tsv):
ID	Source	Change	Target
Guarani0232	Ore ndorombyai kuri	TYPE:AFF	Ore rombyai kuri
Split del dataset: 
Train: Se podría utilizar para un ajuste fino de un LLM.
Dev: Para probar el chatbot y ajustar prompts...
Test: Para evaluar nuestro chatbot y su capacidad de generación en guaraní.
Fuentes de Datos (Guaraní/Jopará): Históricamente, el desarrollo de PLN para estas lenguas ha sido limitado debido a la escasez de grandes corpus monolingües y anotados. Sin embargo, existen documentación sobre su gramática que se suministra a modo de referencia:
Gramática guaraní: Edición 2020, adjunta a la tarea.
Diccionario bilingüe: Guaraní-Español y viceversa, adjunta a la tarea. 
Además de estos 2 documentos, se puede agregar cualquier otra documentación que se crea necesaria o complementaria para la tarea. Del mismo modo, se pueden usar ambos, como preferir uno por sobre el otro, y cotejar resultados según vaya cambiando la base de conocimiento utilizada en el agente conversacional del tipo RAG.
B. Retos y Estrategia de Implementación
La implementación de un agente conversacional (con o sin RAG) para generar texto en guaraní se enfrenta a desafíos intrínsecos de las lenguas de bajos recursos:

Escasez de Datos: Hay una falta de recursos lingüísticos elaborados, lo que requiere un enfoque diferente al utilizado para el inglés u otras lenguas ricas en recursos.
Variación Lingüística y Code-Switching: El Jopará (mezcla guaraní-español) y la variación dialectal y ortográfica presentan dificultades. Las soluciones deben ser creativas para lidiar con el ruido y la variación.
B.1. Estrategia Técnica (Aplicación de PLN Avanzado):
Para el objetivo de generar texto sintético basado en reglas (utilizando los hints recuperados o no por un RAG):

El modelo LLM (experimentar con al menos dos modelos LLM bajo cualquiera de los dos siguientes enfoques):
Transferencia de Aprendizaje (Transfer Learning): Los modelos basados en Transformer han demostrado capacidades de adaptación y rendimiento incluso en entornos de bajos recursos. Con tomar un modelo base (LLM) y ejecutar una exhaustiva tarea de prompt engineering muchas veces es suficiente (como en la clase de "Aprendizaje de zero-shot, few-shot y aprendizaje en contexto con LLM").
Ajuste Fino de Modelos Multilingües: Se podría tomar un modelo existente como Gemma-3 (o Gemma-3n) y realizar un ajuste fino supervisado (SFT) con algún corpus de guaraní disponible (como la clase de "PLN para lenguajes de bajos recursos"), incluso si es limitado (como el corpus de Alpaca traducido al guaraní con Google Translate, combinándolo con la porción de train del de AmericasNLP).
El agente conversacional (se deben implementar ambos enfoques, con al menos dos modelos [según lo comentado arriba], comparando los resultados obtenidos):
RAG sin Contexto Gramatical: El LLM (ajustado para lenguas de bajos recursos, ya sea por prompting o fine tuning) accedería al conocimiento adquirido durante su pre-entrenamiento sobre la documentación de gramática o diccionarios bilingües, permitiéndole generar el texto en guaraní basándose en la información base de su conocimiento general de la lengua.
RAG con Contexto Gramatical: El LLM (ajustado para lenguas de bajos recursos, ya sea por prompting o fine tuning) recibiría, a través del RAG, fragmentos (chunks) de la documentación de gramática o diccionarios bilingües, permitiéndole generar el texto en guaraní basándose en la información fundamentada y precisa recuperada de la base de datos vectorial.
Estos enfoques, aunque simples a priori, permitirían demostrar cómo la implementación de chatbots y asistentes virtuales en contextos de PLN puede superar la escasez de datos mediante la combinación de LLMs, RAG y técnicas de transfer learning. Luego tendríamos que ser capaces de responder principalmente a preguntas como:  ¿Por qué seleccioné estos modelos para mis experimentos? ¿Qué modelo (de los dos seleccionados) es el mejor? ¿Cuál es el mejor enfoque implementado: con o sin RAG, según cada modelo?

B.2. Ejemplo de input (question) y output (answer) del chabot:
Para el ejemplo Guarani0232 (https://github.com/AmericasNLP/americasnlp2025/blob/main/ST2_EducationalMaterials/data/guarani-dev.tsv, se puede formular esta pregunta (question) y obtener esta respuesta (answer):

{"question": "Convert in Guarani the next row data: 
ID	Source 	Change	Target
Guarani0232	Ore ndorombyai kuri	TYPE:AFF	",
"answer": "ID	Source	Change	Target
Guarani0232	Ore ndorombyai kuri	TYPE:AFF	Ore rombyai kuri
"}


	
Diccionario Guaraní-Español  Español-Guaraní.pdf Diccionario Guaraní-Español Español-Guaraní.pdf 
Gramática guaraní.pdf Gramática guaraní.pdf 