{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanAquino22/project_ia/blob/main/projectIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae3ac083",
      "metadata": {
        "id": "ae3ac083"
      },
      "source": [
        "# Sistema de Transformaci√≥n de Oraciones en Guaran√≠ con RAG\n",
        "\n",
        "## Proyecto Final - PLN e IA\n",
        "\n",
        "**üì¶ Repositorio GitHub:** [https://github.com/JuanAquino22/project_ia](https://github.com/JuanAquino22/project_ia)\n",
        "\n",
        "---\n",
        "\n",
        "**Objetivo:** Implementar un sistema capaz de transformar oraciones en guaran√≠ seg√∫n reglas gramaticales espec√≠ficas, comparando el rendimiento de:\n",
        "- 2 modelos de LLM (GPT-3.5 Turbo vs Claude 3.5 Sonnet)\n",
        "- 2 estrategias: **Sin RAG** (conocimiento del modelo) vs **Con RAG** (recuperaci√≥n de documentaci√≥n gramatical)\n",
        "\n",
        "## Dataset: AmericasNLP 2025\n",
        "- **Task:** Transformaci√≥n de oraciones en guaran√≠\n",
        "- **Input:** `Source` (oraci√≥n base) + `Change` (tipo de transformaci√≥n)\n",
        "- **Output:** `Target` (oraci√≥n transformada)\n",
        "\n",
        "**Ejemplo:**\n",
        "```\n",
        "Source: \"Ore ndorombyai kuri\"\n",
        "Change: \"TYPE:AFF\" (convertir a afirmativo)\n",
        "Target: \"Ore rombyai kuri\"\n",
        "```\n",
        "\n",
        "## Metodolog√≠a\n",
        "1.Cargar el dataset AmericasNLP (train/dev/test) para Guaran√≠.\n",
        "2.Construir una base de conocimiento (RAG) con:\n",
        "  * Gram√°tica guaran√≠\n",
        "  * Diccionario guaran√≠‚Äìespa√±ol / espa√±ol‚Äìguaran√≠\n",
        "\n",
        "3.Implementar distintos modos de generaci√≥n:\n",
        "  * Zero-shot y few-shot prompting (sin RAG)\n",
        "\n",
        "  * RAG cl√°sico (vector store con FAISS)\n",
        "\n",
        "  * Hybrid RAG (FAISS + BM25)\n",
        "\n",
        "4.(Opcional) Entrenar un modelo open-source mediante fine-tuning supervisado (SFT) usando el split train.\n",
        "\n",
        "5.Evaluar en dev y test usando m√©tricas objetivas:\n",
        "\n",
        "  * Accuracy (exact match)\n",
        "\n",
        "  * BLEU\n",
        "\n",
        "Comparar modelos y estrategias, discutiendo ventajas y limitaciones en el contexto de una lengua de bajos recursos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d478c8",
      "metadata": {
        "id": "e1d478c8"
      },
      "source": [
        "## 1. Instalaci√≥n de Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "901e611d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901e611d",
        "outputId": "45e815ac-0e67-4f09-f71d-6aae03c4e5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Instalando dependencias compatibles con Python 3.12...\n",
            "‚úì Dependencias instaladas correctamente (Python 3.12 compatible)\n"
          ]
        }
      ],
      "source": [
        "print(\"üì¶ Instalando dependencias compatibles con Python 3.12...\")\n",
        "\n",
        "!pip install -q \\\n",
        "  langchain==0.3.0 \\\n",
        "  langchain-community==0.3.0 \\\n",
        "  langchain-text-splitters==0.3.0 \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  rank-bm25 \\\n",
        "  pymupdf pandas sacrebleu nltk \\\n",
        "  huggingface_hub tqdm\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "print(\"‚úì Dependencias instaladas correctamente (Python 3.12 compatible)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "617f1755",
      "metadata": {
        "id": "617f1755"
      },
      "source": [
        "## 2. Importaciones y Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "52cd9de9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52cd9de9",
        "outputId": "1fac88b4-6e16-4ada-b588-dd56accf34de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Importaciones completadas correctamente (compatible con Py3.12)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import fitz  # PyMuPDF\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# LangChain\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# BM25 manual\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# M√©tricas\n",
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "# Transformers (solo inferencia, NO fine-tuning en Py3.12)\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "print(\"‚úì Importaciones completadas correctamente (compatible con Py3.12)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d012fbbc",
      "metadata": {
        "id": "d012fbbc"
      },
      "source": [
        "## 3. Configuraci√≥n de API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eb5d0773",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb5d0773",
        "outputId": "7802c074-25df-4341-f2c7-8e887969c098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenRouter KEY cargada: True\n",
            "HF_TOKEN cargado: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# OpenRouter API\n",
        "openrouter_key = userdata.get(\"OPENROUTER\")\n",
        "if openrouter_key and len(openrouter_key) > 5:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = openrouter_key\n",
        "else:\n",
        "    raise ValueError(\"ERROR: No se encontr√≥ la clave OPENROUTER en Colab Secrets\")\n",
        "\n",
        "# Hugging Face token (opcional)\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "if hf_token and len(hf_token) > 5:\n",
        "    os.environ[\"HF_TOKEN\"] = hf_token\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_token\n",
        "else:\n",
        "    print(\"Advertencia: no se encontr√≥ HF_TOKEN (solo afecta a modelos HF opcionales)\")\n",
        "\n",
        "\n",
        "print(\"OpenRouter KEY cargada:\", bool(os.environ.get(\"OPENROUTER_API_KEY\")))\n",
        "print(\"HF_TOKEN cargado:\", bool(os.environ.get(\"HF_TOKEN\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d829a5e",
      "metadata": {
        "id": "6d829a5e"
      },
      "source": [
        "## 4. Descarga del Dataset AmericasNLP\n",
        "\n",
        "Dataset oficial: https://github.com/AmericasNLP/americasnlp2025/tree/main/ST2_EducationalMaterials/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1abf2d1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "1abf2d1f",
        "outputId": "521f2ef7-7bb1-43e0-a22d-9ce5c1846b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando datasets...\n",
            "\n",
            "‚úì TRAIN: 178 ejemplos | Columnas: ['ID', 'Source', 'Change', 'Target']\n",
            "‚úì DEV: 79 ejemplos | Columnas: ['ID', 'Source', 'Change', 'Target']\n",
            "‚úì TEST: 364 ejemplos | Columnas: ['ID', 'Source', 'Change', 'Target']\n",
            "\n",
            "============================================================\n",
            "EJEMPLO DEV (primeras 3 filas):\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"datasets[\\\"dev\\\"]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Guarani0232\",\n          \"Guarani0233\",\n          \"Guarani0234\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ore ndorombyai kuri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Change\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TYPE:AFF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Ore rombyai kuri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c2e44853-4654-496b-a351-a49b3ee730b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Source</th>\n",
              "      <th>Change</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Guarani0232</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>TYPE:AFF</td>\n",
              "      <td>Ore rombyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guarani0233</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>TENSE:FUT_SIM</td>\n",
              "      <td>Ore ndorombyaita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Guarani0234</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>PERSON:1_PL_INC</td>\n",
              "      <td>√ëande na√±ambyai kuri</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2e44853-4654-496b-a351-a49b3ee730b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2e44853-4654-496b-a351-a49b3ee730b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2e44853-4654-496b-a351-a49b3ee730b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8b46c0de-887c-470f-8067-48e5734ecf90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b46c0de-887c-470f-8067-48e5734ecf90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8b46c0de-887c-470f-8067-48e5734ecf90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            ID               Source           Change                Target\n",
              "0  Guarani0232  Ore ndorombyai kuri         TYPE:AFF      Ore rombyai kuri\n",
              "1  Guarani0233  Ore ndorombyai kuri    TENSE:FUT_SIM      Ore ndorombyaita\n",
              "2  Guarani0234  Ore ndorombyai kuri  PERSON:1_PL_INC  √ëande na√±ambyai kuri"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# URLs del dataset\n",
        "BASE_URL = \"https://raw.githubusercontent.com/AmericasNLP/americasnlp2025/main/ST2_EducationalMaterials/data/\"\n",
        "\n",
        "datasets_urls = {\n",
        "    \"train\": f\"{BASE_URL}guarani-train.tsv\",\n",
        "    \"dev\":   f\"{BASE_URL}guarani-dev.tsv\",\n",
        "    \"test\":  f\"{BASE_URL}guarani-test.tsv\"\n",
        "}\n",
        "\n",
        "def load_dataset(url: str) -> pd.DataFrame:\n",
        "    \"\"\"Descarga archivo TSV desde GitHub de forma segura.\"\"\"\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    return pd.read_csv(StringIO(r.text), sep=\"\\t\")\n",
        "\n",
        "print(\"Descargando datasets...\\n\")\n",
        "datasets = {}\n",
        "\n",
        "for split, url in datasets_urls.items():\n",
        "    try:\n",
        "        df = load_dataset(url)\n",
        "        datasets[split] = df\n",
        "        print(f\"‚úì {split.upper()}: {len(df)} ejemplos | Columnas: {list(df.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error cargando {split}: {e}\")\n",
        "\n",
        "# Vista previa\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EJEMPLO DEV (primeras 3 filas):\")\n",
        "print(\"=\"*60)\n",
        "datasets[\"dev\"].head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37797eec",
      "metadata": {
        "id": "37797eec"
      },
      "source": [
        "## 5. Carga de Gram√°tica Guaran√≠ (Base de Conocimiento para RAG)\n",
        "\n",
        "**Nota:** Sube el archivo Gram√°tica guaran√≠ y Diccionario a Colab o usa Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "58f2674a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58f2674a",
        "outputId": "d24cb0c2-e93e-4a77-9b86-fad91f2bf9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Archivos cargados desde /content\n",
            "Gram√°tica: /content/Gram√°tica guaran√≠.pdf\n",
            "Diccionario: /content/Diccionario Guaran√≠-Espa√±ol  Espa√±ol-Guaran√≠.pdf\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "PDF_GRAMMAR = \"/content/Gram√°tica guaran√≠.pdf\"\n",
        "PDF_DICT    = \"/content/Diccionario Guaran√≠-Espa√±ol  Espa√±ol-Guaran√≠.pdf\"\n",
        "\n",
        "print(\"‚úì Archivos cargados desde /content\")\n",
        "print(\"Gram√°tica:\", PDF_GRAMMAR)\n",
        "print(\"Diccionario:\", PDF_DICT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cG4yFmb6W7MX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG4yFmb6W7MX",
        "outputId": "73c7258c-dd52-40d8-fc9f-d47157335b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò Extrayendo texto de: /content/Gram√°tica guaran√≠.pdf\n",
            "   Total de p√°ginas: 260\n",
            "   ‚Ä¢ Procesadas 10 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 20 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 30 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 40 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 50 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 60 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 70 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 80 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 90 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 100 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 110 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 120 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 130 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 140 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 150 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 160 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 170 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 180 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 190 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 200 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 210 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 220 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 230 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 240 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 250 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 260 p√°ginas...\n",
            "‚úì Extracci√≥n completada\n",
            "üìò Extrayendo texto de: /content/Diccionario Guaran√≠-Espa√±ol  Espa√±ol-Guaran√≠.pdf\n",
            "   Total de p√°ginas: 218\n",
            "   ‚Ä¢ Procesadas 10 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 20 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 30 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 40 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 50 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 60 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 70 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 80 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 90 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 100 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 110 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 120 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 130 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 140 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 150 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 160 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 170 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 180 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 190 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 200 p√°ginas...\n",
            "   ‚Ä¢ Procesadas 210 p√°ginas...\n",
            "‚úì Extracci√≥n completada\n",
            "\n",
            " MUESTRA (primeros 500 caracteres):\n",
            "GUARANI √ëE‚Äô·∫º  REREKUAPAV·∫º (G√ëR)\n",
            "ACADEMIA DE  LA  LENGUA GUARAN√ç (ALG)\n",
            "GUARANI √ëE‚Äô·∫ºTEKUAA\n",
            "GRAM√ÅTICA GUARAN√ç\n",
            "Versi√≥n corregida 2020\n",
            "Asunci√≥n, Paraguay\n",
            " ¬©  Guarani √ëe‚Äô√´ Rerekuapav√´\n",
            "      Academia de la Lengua Guarani\n",
            " EDITORIAL SERVILIBRO\n",
            "25 de Mayo Esq. M√©xico\n",
            "Telefax: (595‚Äì21) 444 770\n",
            "Plaza Uruguaya‚Äì Asunci√≥n ‚Äì Paraguay\n",
            "E‚Äìmail: servilibro@gmail.com\n",
            "www.servilibro.com.py\n",
            "Direcci√≥n editorial: Vidalia S√°nchez\n",
            "Correcci√≥n: Dionisio Fleitas, Carlos Ferreira Qui√±onez, \n",
            "Juan F√©lix Gonz√°lez y Modesto Rome...\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Extrae texto de un PDF (solo texto, sin OCR).\"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        raise FileNotFoundError(f\" Archivo no encontrado: {pdf_path}\")\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "\n",
        "    print(f\"üìò Extrayendo texto de: {pdf_path}\")\n",
        "    print(f\"   Total de p√°ginas: {len(doc)}\")\n",
        "\n",
        "    for page_num, page in enumerate(doc, start=1):\n",
        "        try:\n",
        "            text += page.get_text()\n",
        "        except Exception as e:\n",
        "            print(f\" Error leyendo p√°gina {page_num}: {e}\")\n",
        "\n",
        "        if page_num % 10 == 0:\n",
        "            print(f\"   ‚Ä¢ Procesadas {page_num} p√°ginas...\")\n",
        "\n",
        "    doc.close()\n",
        "    print(\"‚úì Extracci√≥n completada\")\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# Extraer texto de gram√°tica y diccionario\n",
        "grammar_text = extract_text_from_pdf(PDF_GRAMMAR)\n",
        "dict_text    = extract_text_from_pdf(PDF_DICT)\n",
        "\n",
        "print(\"\\n MUESTRA (primeros 500 caracteres):\")\n",
        "print(grammar_text[:500] + \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ad40bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ad40bc1",
        "outputId": "3384c515-4de1-4329-e0e5-ae24ac115ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Dividiendo texto en chunks...\n",
            "‚úì Creados 1400 chunks\n",
            "  Longitud promedio: 629 caracteres\n",
            "  Longitud m√≠nima: 376\n",
            "  Longitud m√°xima: 649\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# 1) LIMPIEZA DEL TEXTO\n",
        "\n",
        "def clean_text(txt):\n",
        "    # Quitar m√∫ltiples espacios\n",
        "    txt = re.sub(r\"[ ]{2,}\", \" \", txt)\n",
        "\n",
        "    # Quitar saltos de l√≠nea repetidos\n",
        "    txt = re.sub(r\"\\n{2,}\", \"\\n\", txt)\n",
        "\n",
        "    # Quitar headers y footers comunes de PDFs\n",
        "    txt = re.sub(r\"P√°gina \\d+|\\d+ / \\d+\", \"\", txt)\n",
        "\n",
        "    # Quitar caracteres sueltos o rotos\n",
        "    txt = txt.replace(\"ÔøΩ\", \"\")\n",
        "\n",
        "    return txt.strip()\n",
        "\n",
        "\n",
        "grammar_clean = clean_text(grammar_text)\n",
        "dict_clean    = clean_text(dict_text)\n",
        "\n",
        "# 2) CONCATENAR DE FORMA M√ÅS ESTRUCTURADA\n",
        "\n",
        "combined_text = (\n",
        "    \"### SECCI√ìN: GRAM√ÅTICA GUARAN√ç\\n\" +\n",
        "    grammar_clean +\n",
        "    \"\\n\\n### SECCI√ìN: DICCIONARIO GUARAN√ç‚ÄìESPA√ëOL\\n\" +\n",
        "    dict_clean\n",
        ")\n",
        "\n",
        "# 3) CHUNKING OPTIMIZADO\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=650,       # menor = m√°s precisi√≥n sem√°ntica\n",
        "    chunk_overlap=120,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n##\", \"\\n\\n\", \"\\n\", \". \", \" \"]\n",
        ")\n",
        "\n",
        "print(\"üìö Dividiendo texto en chunks...\")\n",
        "text_chunks = text_splitter.split_text(combined_text)\n",
        "\n",
        "# Remover chunks vac√≠os\n",
        "text_chunks = [c for c in text_chunks if c.strip() and len(c) > 80]\n",
        "\n",
        "# 4) CREAR DOCUMENTOS\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=chunk,\n",
        "        metadata={\n",
        "            \"source\": \"corpus_guarani\",\n",
        "            \"chunk_id\": idx,\n",
        "            \"length\": len(chunk)\n",
        "        }\n",
        "    )\n",
        "    for idx, chunk in enumerate(text_chunks)\n",
        "]\n",
        "\n",
        "print(f\"‚úì Creados {len(documents)} chunks\")\n",
        "print(f\"  Longitud promedio: {sum(len(c) for c in text_chunks)//len(text_chunks)} caracteres\")\n",
        "print(f\"  Longitud m√≠nima: {min(len(c) for c in text_chunks)}\")\n",
        "print(f\"  Longitud m√°xima: {max(len(c) for c in text_chunks)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10bcd20",
      "metadata": {
        "id": "b10bcd20"
      },
      "source": [
        "## 6. Construcci√≥n del Vector Store (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "757305bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757305bf",
        "outputId": "320b39a4-20b2-4c73-a58a-3f7a1985c7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Analizando secciones relevantes de la gram√°tica...\n",
            "\n",
            " Frecuencia de palabras clave encontradas:\n",
            "  negaci√≥n        ‚Üí 9 ocurrencias\n",
            "  negativo        ‚Üí 1 ocurrencias\n",
            "  ndi             ‚Üí 279 ocurrencias\n",
            "  ndaje           ‚Üí 36 ocurrencias\n",
            "  ndai            ‚Üí 11 ocurrencias\n",
            "  afirmativo      ‚Üí 1 ocurrencias\n",
            "  afirmaci√≥n      ‚Üí 2 ocurrencias\n",
            "  pret√©rito       ‚Üí 8 ocurrencias\n",
            "  pasado          ‚Üí 5 ocurrencias\n",
            "  kuri            ‚Üí 60 ocurrencias\n",
            "  futuro          ‚Üí 11 ocurrencias\n",
            "  ta              ‚Üí 1261 ocurrencias\n",
            "  persona         ‚Üí 86 ocurrencias\n",
            "  1a persona      ‚Üí 0 ocurrencias\n",
            "  2a persona      ‚Üí 0 ocurrencias\n",
            "  3a persona      ‚Üí 0 ocurrencias\n",
            "  prefijo         ‚Üí 15 ocurrencias\n",
            "  sufijo          ‚Üí 10 ocurrencias\n",
            "  morfolog√≠a      ‚Üí 2 ocurrencias\n",
            "  verbo           ‚Üí 262 ocurrencias\n",
            "  tiempo          ‚Üí 34 ocurrencias\n",
            "  aspecto         ‚Üí 12 ocurrencias\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\" Analizando secciones relevantes de la gram√°tica...\")\n",
        "\n",
        "important_keywords = [\n",
        "    \"negaci√≥n\", \"negativo\", \"ndi\", \"ndaje\", \"ndai\",\n",
        "    \"afirmativo\", \"afirmaci√≥n\",\n",
        "    \"pret√©rito\", \"pasado\", \"kuri\",\n",
        "    \"futuro\", \"ta\",\n",
        "    \"persona\", \"1a persona\", \"2a persona\", \"3a persona\",\n",
        "    \"prefijo\", \"sufijo\", \"morfolog√≠a\", \"verbo\",\n",
        "    \"tiempo\", \"aspecto\"\n",
        "]\n",
        "\n",
        "# NO modificamos documentos, solo analizamos frecuencias\n",
        "keyword_hits = {k: grammar_text.lower().count(k.lower()) for k in important_keywords}\n",
        "\n",
        "print(\"\\n Frecuencia de palabras clave encontradas:\")\n",
        "for k, v in keyword_hits.items():\n",
        "    print(f\"  {k:15} ‚Üí {v} ocurrencias\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eZBc8fAGbuGj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZBc8fAGbuGj",
        "outputId": "ac25d761-68ef-463f-f814-6f94acd48071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Cargando modelo de embeddings (simple y estable)...\n",
            "‚úì Embeddings listos (hash-based, FAISS compatible, sin dependencias)\n"
          ]
        }
      ],
      "source": [
        "print(\"üîπ Cargando modelo de embeddings (simple y estable)...\")\n",
        "\n",
        "# Vector fijo de alta dimensionalidad basado en hashing (sin modelos)\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "class SimpleHashEmbedding:\n",
        "    def __init__(self, dim=384):\n",
        "        self.dim = dim\n",
        "\n",
        "    def _hash_vector(self, text):\n",
        "        h = hashlib.sha256(text.encode()).digest()\n",
        "        arr = np.frombuffer(h, dtype=np.uint8)\n",
        "        base = np.resize(arr, self.dim)\n",
        "        return (base / 255).astype(float).tolist()\n",
        "\n",
        "    def embed_documents(self, docs):\n",
        "        return [self._hash_vector(d) for d in docs]\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        return self._hash_vector(text)\n",
        "\n",
        "embeddings = SimpleHashEmbedding()\n",
        "\n",
        "print(\"‚úì Embeddings listos (hash-based, FAISS compatible, sin dependencias)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c6ef6553",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6ef6553",
        "outputId": "1d58dc10-79d0-44ea-c81a-5b70650f58da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîπ Creando vector store con FAISS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì FAISS listo (k=3)\n",
            "\n",
            "üîπ Configurando BM25 Retriever...\n",
            "‚úì BM25 listo (top-3)\n",
            "\n",
            "üîπ Configurando Hybrid Ensemble Retriever...\n",
            "‚úì Hybrid RAG listo (BM25 + FAISS)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# FAISS + BM25 + HYBRID RETRIEVER\n",
        "# ==============================================================\n",
        "\n",
        "print(\"\\nüîπ Creando vector store con FAISS...\")\n",
        "\n",
        "# FAISS usa tus embeddings hash-based sin problema\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "retriever_faiss = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}\n",
        ")\n",
        "\n",
        "print(\"‚úì FAISS listo (k=3)\")\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# BM25 RETRIEVER (rank_bm25)\n",
        "# ==============================================================\n",
        "\n",
        "print(\"\\nüîπ Configurando BM25 Retriever...\")\n",
        "\n",
        "# BM25Okapi espera lista de tokens por documento\n",
        "tokenized_docs = [doc.page_content.lower().split() for doc in documents]\n",
        "bm25 = BM25Okapi(tokenized_docs)\n",
        "\n",
        "class BM25RetrieverWrapper:\n",
        "    def __init__(self, docs, tokenizer, bm25):\n",
        "        self.docs = docs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bm25 = bm25\n",
        "\n",
        "    def invoke(self, query):\n",
        "        tokens = query.lower().split()\n",
        "        scores = self.bm25.get_scores(tokens)\n",
        "\n",
        "        # Top-3\n",
        "        top_idx = scores.argsort()[-3:][::-1]\n",
        "        return [self.docs[i] for i in top_idx]\n",
        "\n",
        "bm25_retriever = BM25RetrieverWrapper(documents, None, bm25)\n",
        "\n",
        "print(\"‚úì BM25 listo (top-3)\")\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# HYBRID (BM25 + FAISS)\n",
        "# ==============================================================\n",
        "\n",
        "print(\"\\nüîπ Configurando Hybrid Ensemble Retriever...\")\n",
        "\n",
        "class SimpleEnsembleRetriever:\n",
        "    def __init__(self, retrievers, weights):\n",
        "        self.retrievers = retrievers\n",
        "        self.weights = weights\n",
        "\n",
        "    def invoke(self, query):\n",
        "        combined = []\n",
        "\n",
        "        # Ejecutar cada retriever\n",
        "        for retriever, weight in zip(self.retrievers, self.weights):\n",
        "            docs = retriever.invoke(query) or []\n",
        "            for d in docs:\n",
        "                combined.append((d, weight))\n",
        "\n",
        "        if not combined:\n",
        "            return []\n",
        "\n",
        "        # Acumular puntaje por contenido\n",
        "        score_map = {}\n",
        "        doc_map = {}\n",
        "\n",
        "        for doc, weight in combined:\n",
        "            key = doc.page_content[:150]  # clave estable\n",
        "            score_map[key] = score_map.get(key, 0) + weight\n",
        "            doc_map[key] = doc\n",
        "\n",
        "        # Ordenar por puntaje\n",
        "        sorted_keys = sorted(score_map, key=lambda k: -score_map[k])\n",
        "\n",
        "        return [doc_map[k] for k in sorted_keys[:3]]\n",
        "\n",
        "\n",
        "ensemble_retriever = SimpleEnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, retriever_faiss],\n",
        "    weights=[0.6, 0.4]   # Prioridad a BM25 para lenguas de bajo recurso\n",
        ")\n",
        "\n",
        "print(\"‚úì Hybrid RAG listo (BM25 + FAISS)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be306c70",
      "metadata": {
        "id": "be306c70"
      },
      "source": [
        "## 7. Wrapper para OpenRouter (GPT-3.5 y Claude 3.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "37a4e0b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37a4e0b7",
        "outputId": "bd703097-00c1-45d4-86eb-fe249aba71c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Modelos configurados:\n",
            "  - GPT-3.5 Turbo (OpenAI)\n",
            "  - Claude 3.5 Sonnet (Anthropic)\n"
          ]
        }
      ],
      "source": [
        "class OpenRouterLLM:\n",
        "    \"\"\"Wrapper estable para usar modelos v√≠a OpenRouter.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, api_key: str):\n",
        "        self.model_name = model_name\n",
        "        self.api_key = api_key\n",
        "        self.api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    def generate(self, prompt: str, max_tokens: int = 200, temperature: float = 0.2) -> str:\n",
        "        \"\"\"\n",
        "        Env√≠a un prompt al modelo y devuelve SOLO la oraci√≥n generada.\n",
        "        Maneja errores y limpia la salida.\n",
        "        \"\"\"\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"HTTP-Referer\": \"https://colab.research.google.com/\",\n",
        "            \"X-Title\": \"guarani-transformation\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"Eres un modelo experto en transformar oraciones en guaran√≠ \"\n",
        "                        \"seg√∫n reglas gramaticales. \"\n",
        "                        \"Responde SIEMPRE con una √∫nica oraci√≥n, sin explicaciones.\"\n",
        "                    )\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"max_tokens\": max_tokens,\n",
        "            \"temperature\": temperature\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.api_url, headers=headers, json=payload, timeout=60)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                return f\"[Error {response.status_code}] {response.text}\"\n",
        "\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "            # Limpiar salida\n",
        "            if isinstance(content, str):\n",
        "                return content.strip().split(\"\\n\")[0]  # solo la primera l√≠nea\n",
        "            return str(content).strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"[Exception] {str(e)}\"\n",
        "\n",
        "\n",
        "# === CONFIGURACI√ìN DE MODELOS ===\n",
        "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "model_gpt35 = OpenRouterLLM(\"openai/gpt-3.5-turbo\", api_key)\n",
        "model_claude = OpenRouterLLM(\"anthropic/claude-3.5-sonnet\", api_key)\n",
        "\n",
        "print(\"‚úì Modelos configurados:\")\n",
        "print(\"  - GPT-3.5 Turbo (OpenAI)\")\n",
        "print(\"  - Claude 3.5 Sonnet (Anthropic)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ac718f",
      "metadata": {
        "id": "b2ac718f"
      },
      "source": [
        "## 8. Sistema de Transformaci√≥n de Oraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "19a96494",
      "metadata": {
        "id": "19a96494"
      },
      "outputs": [],
      "source": [
        "class GuaraniTransformationSystem:\n",
        "    \"\"\"Sistema de transformaci√≥n de oraciones en guaran√≠ seg√∫n el dataset AmericasNLP.\"\"\"\n",
        "\n",
        "    def __init__(self, llm, retriever=None, strategy=\"zero-shot\"):\n",
        "        self.llm = llm\n",
        "        self.retriever = retriever\n",
        "        self.strategy = strategy.lower()\n",
        "\n",
        "        # Reglas reales del dataset\n",
        "        self.rule_dict = {\n",
        "            \"TYPE:AFF\": \"Convierte una oraci√≥n negativa (ndo-‚Ä¶-i) en afirmativa removiendo la negaci√≥n.\",\n",
        "            \"TYPE:NEG\": \"Convierte oraci√≥n afirmativa en negativa usando ndo- y -i.\",\n",
        "            \"TENSE:FUT_SIM\": \"Transforma el verbo al futuro simple agregando -ta.\",\n",
        "            \"TENSE:PAST\": \"Convierte la oraci√≥n al pasado usando kuri.\",\n",
        "            \"PERSON:1_PL_INC\": \"Cambia sujeto a primera persona plural inclusiva (√±ande).\",\n",
        "            \"PERSON:1_PL_EXC\": \"Cambia sujeto a primera persona plural exclusiva (ore).\",\n",
        "            \"PERSON:3\": \"Cambia el sujeto a tercera persona singular (ha'e).\"\n",
        "        }\n",
        "\n",
        "        # Few-shot\n",
        "        self.few_shot = \"\"\"\n",
        "Ejemplos:\n",
        "Input: Ore ndorombyai kuri | Change: TYPE:AFF\n",
        "Output: Ore rombyai kuri\n",
        "\n",
        "Input: Ore ndorombyai kuri | Change: TENSE:FUT_SIM\n",
        "Output: Ore ndorombyaita\n",
        "\n",
        "Input: Ore ndorombyai kuri | Change: PERSON:1_PL_INC\n",
        "Output: √ëande √±ambyai kuri\n",
        "\"\"\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # LIMPIEZA DE SALIDA\n",
        "    # -----------------------------\n",
        "    def _clean(self, text: str):\n",
        "        if not isinstance(text, str):\n",
        "            return \"\"\n",
        "        text = text.strip()\n",
        "        for tag in [\"Output:\", \"output:\", \"Respuesta:\", \"respuesta:\"]:\n",
        "            text = text.replace(tag, \"\")\n",
        "        return text.split(\"\\n\")[0].replace('\"', \"\").strip()\n",
        "\n",
        "    # -----------------------------\n",
        "    # MODELOS SIN RAG\n",
        "    # -----------------------------\n",
        "    def _transform_basic(self, source: str, change: str, few: bool):\n",
        "        rule_expl = self.rule_dict.get(change, \"Regla no documentada.\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Transforma la oraci√≥n en guaran√≠ seg√∫n la regla dada.\n",
        "\n",
        "Regla: {change}\n",
        "Descripci√≥n: {rule_expl}\n",
        "\n",
        "{self.few_shot if few else \"\"}\n",
        "\n",
        "Oraci√≥n original: {source}\n",
        "\n",
        "Responde SOLO con la oraci√≥n transformada:\n",
        "\"\"\"\n",
        "        return self._clean(self.llm.generate(prompt))\n",
        "\n",
        "    # -----------------------------\n",
        "    # MODELOS CON RAG\n",
        "    # -----------------------------\n",
        "    def _transform_rag(self, source: str, change: str, few: bool):\n",
        "        rule_expl = self.rule_dict.get(change, \"Regla no documentada.\")\n",
        "\n",
        "        query = f\"transformaci√≥n {change} guaran√≠ ejemplo negaci√≥n afirmaci√≥n tiempo persona sujeto\"\n",
        "\n",
        "        docs = []\n",
        "        if self.retriever:\n",
        "            try:\n",
        "                docs = self.retriever.invoke(query)\n",
        "            except:\n",
        "                docs = []\n",
        "\n",
        "        context = \"\\n\".join([d.page_content[:300] for d in docs]) or \"No hay contexto √∫til.\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Usa el siguiente contexto gramatical para transformar la oraci√≥n:\n",
        "\n",
        "CONTEXTO:\n",
        "{context}\n",
        "\n",
        "Regla: {change}\n",
        "Descripci√≥n: {rule_expl}\n",
        "\n",
        "{self.few_shot if few else \"\"}\n",
        "\n",
        "Oraci√≥n original: {source}\n",
        "\n",
        "Responde SOLO con la oraci√≥n transformada:\n",
        "\"\"\"\n",
        "        return self._clean(self.llm.generate(prompt))\n",
        "\n",
        "    # -----------------------------\n",
        "    # M√âTODO P√öBLICO PRINCIPAL\n",
        "    # -----------------------------\n",
        "    def transform(self, source: str, change: str):\n",
        "        use_rag = \"rag\" in self.strategy\n",
        "        use_few = \"few\" in self.strategy\n",
        "\n",
        "        if use_rag:\n",
        "            return self._transform_rag(source, change, use_few)\n",
        "        else:\n",
        "            return self._transform_basic(source, change, use_few)\n",
        "\n",
        "    # -----------------------------\n",
        "    # EVALUACI√ìN DEL DATASET\n",
        "    # -----------------------------\n",
        "    def evaluate_dataset(self, df):\n",
        "        results = []\n",
        "        for _, row in df.iterrows():\n",
        "            source = row[\"Source\"]\n",
        "            change = row[\"Change\"]\n",
        "            target = row[\"Target\"]\n",
        "\n",
        "            prediction = self.transform(source, change)\n",
        "            correct = prediction.lower().strip() == target.lower().strip()\n",
        "\n",
        "            results.append({\n",
        "                \"id\": row[\"ID\"],\n",
        "                \"source\": source,\n",
        "                \"change\": change,\n",
        "                \"target\": target,\n",
        "                \"prediction\": prediction,\n",
        "                \"correct\": correct\n",
        "            })\n",
        "\n",
        "            time.sleep(0.3)\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d61f37c",
      "metadata": {
        "id": "0d61f37c"
      },
      "source": [
        "## 9. Evaluaci√≥n de Modelos\n",
        "\n",
        "Se evaluar√°n ambos modelos (GPT-3.5 y Claude 3.5) con y sin RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "XjRsVfG2MnHK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XjRsVfG2MnHK",
        "outputId": "64e7213c-577d-42bc-be09-0081e9962044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì dev_data cargado correctamente:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dev_data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Guarani0075\",\n          \"Guarani0233\",\n          \"Guarani0237\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Pe\\u1ebd nape\\u00f1anga\\u2019uta\",\n          \"Ore ndorombyai kuri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Change\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"TENSE:FUT_SIM\",\n          \"PERSON:2_SI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Che na\\u00f1anga\\u2019uta\",\n          \"Ore ndorombyaita\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dev_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-87aec582-763e-43e9-a5ad-7d5760bddb4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Source</th>\n",
              "      <th>Change</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Guarani0232</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>TYPE:AFF</td>\n",
              "      <td>Ore rombyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guarani0233</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>TENSE:FUT_SIM</td>\n",
              "      <td>Ore ndorombyaita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Guarani0234</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>PERSON:1_PL_INC</td>\n",
              "      <td>√ëande na√±ambyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Guarani0235</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>PERSON:1_SI</td>\n",
              "      <td>Che nambyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Guarani0236</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>PERSON:2_PL</td>\n",
              "      <td>Pe·∫Ω napembyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Guarani0237</td>\n",
              "      <td>Ore ndorombyai kuri</td>\n",
              "      <td>PERSON:2_SI</td>\n",
              "      <td>Nde nerembyai kuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Guarani0073</td>\n",
              "      <td>Pe·∫Ω nape√±anga‚Äôuta</td>\n",
              "      <td>TYPE:AFF</td>\n",
              "      <td>Pe·∫Ω pe√±anga‚Äôuta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Guarani0074</td>\n",
              "      <td>Pe·∫Ω nape√±anga‚Äôuta</td>\n",
              "      <td>PERSON:3_PL</td>\n",
              "      <td>Ha‚Äôeku√©ra ndo√±anga‚Äôuta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Guarani0075</td>\n",
              "      <td>Pe·∫Ω nape√±anga‚Äôuta</td>\n",
              "      <td>PERSON:1_SI</td>\n",
              "      <td>Che na√±anga‚Äôuta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Guarani0076</td>\n",
              "      <td>Pe·∫Ω nape√±anga‚Äôuta</td>\n",
              "      <td>TENSE:PAS_REC</td>\n",
              "      <td>Pe·∫Ω nape√±anga‚Äôui kuri</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87aec582-763e-43e9-a5ad-7d5760bddb4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87aec582-763e-43e9-a5ad-7d5760bddb4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87aec582-763e-43e9-a5ad-7d5760bddb4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35120a78-6a88-4e03-976e-6e80ea7b2ac4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35120a78-6a88-4e03-976e-6e80ea7b2ac4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35120a78-6a88-4e03-976e-6e80ea7b2ac4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f69bc15a-90bc-4468-9772-ce5bd038e154\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dev_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f69bc15a-90bc-4468-9772-ce5bd038e154 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dev_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            ID               Source           Change                  Target\n",
              "0  Guarani0232  Ore ndorombyai kuri         TYPE:AFF        Ore rombyai kuri\n",
              "1  Guarani0233  Ore ndorombyai kuri    TENSE:FUT_SIM        Ore ndorombyaita\n",
              "2  Guarani0234  Ore ndorombyai kuri  PERSON:1_PL_INC    √ëande na√±ambyai kuri\n",
              "3  Guarani0235  Ore ndorombyai kuri      PERSON:1_SI        Che nambyai kuri\n",
              "4  Guarani0236  Ore ndorombyai kuri      PERSON:2_PL      Pe·∫Ω napembyai kuri\n",
              "5  Guarani0237  Ore ndorombyai kuri      PERSON:2_SI      Nde nerembyai kuri\n",
              "6  Guarani0073    Pe·∫Ω nape√±anga‚Äôuta         TYPE:AFF         Pe·∫Ω pe√±anga‚Äôuta\n",
              "7  Guarani0074    Pe·∫Ω nape√±anga‚Äôuta      PERSON:3_PL  Ha‚Äôeku√©ra ndo√±anga‚Äôuta\n",
              "8  Guarani0075    Pe·∫Ω nape√±anga‚Äôuta      PERSON:1_SI         Che na√±anga‚Äôuta\n",
              "9  Guarani0076    Pe·∫Ω nape√±anga‚Äôuta    TENSE:PAS_REC   Pe·∫Ω nape√±anga‚Äôui kuri"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# DEFINIR dev_data PARA EVALUACI√ìN\n",
        "\n",
        "# Tomamos 10 ejemplos para no gastar tokens en pruebas\n",
        "dev_data = datasets[\"dev\"].head(10)\n",
        "\n",
        "print(\"‚úì dev_data cargado correctamente:\")\n",
        "display(dev_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "88e46c43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88e46c43",
        "outputId": "1ff75357-fec2-448f-d8d1-eacbacde7418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EVALUACI√ìN EXTENDIDA (Zero-Shot vs Few-Shot vs Hybrid RAG)\n",
            "======================================================================\n",
            "\n",
            "================ GPT-3.5 Turbo ================\n",
            "\n",
            "Evaluando: GPT-3.5 Turbo - Zero-Shot ...\n",
            "‚úì GPT-3.5 Turbo - Zero-Shot: 0.00% accuracy (0/10)\n",
            "Evaluando: GPT-3.5 Turbo - Few-Shot ...\n",
            "‚úì GPT-3.5 Turbo - Few-Shot: 10.00% accuracy (1/10)\n",
            "Evaluando: GPT-3.5 Turbo - Semantic RAG ...\n",
            "‚úì GPT-3.5 Turbo - Semantic RAG: 0.00% accuracy (0/10)\n",
            "Evaluando: GPT-3.5 Turbo - Hybrid RAG ...\n",
            "‚úì GPT-3.5 Turbo - Hybrid RAG: 10.00% accuracy (1/10)\n",
            "\n",
            "================ Claude 3.5 Sonnet ================\n",
            "\n",
            "Evaluando: Claude 3.5 Sonnet - Zero-Shot ...\n",
            "‚úì Claude 3.5 Sonnet - Zero-Shot: 30.00% accuracy (3/10)\n",
            "Evaluando: Claude 3.5 Sonnet - Few-Shot ...\n",
            "‚úì Claude 3.5 Sonnet - Few-Shot: 50.00% accuracy (5/10)\n",
            "Evaluando: Claude 3.5 Sonnet - Semantic RAG ...\n",
            "‚úì Claude 3.5 Sonnet - Semantic RAG: 20.00% accuracy (2/10)\n",
            "Evaluando: Claude 3.5 Sonnet - Hybrid RAG ...\n",
            "‚úì Claude 3.5 Sonnet - Hybrid RAG: 40.00% accuracy (4/10)\n",
            "\n",
            "‚úì Evaluaci√≥n completa\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EVALUACI√ìN EXTENDIDA (Zero-Shot vs Few-Shot vs Hybrid RAG)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Estrategias a evaluar\n",
        "strategies = [\n",
        "    (\"Zero-Shot\", None, \"zero-shot\"),\n",
        "    (\"Few-Shot\", None, \"few-shot\"),\n",
        "    (\"Semantic RAG\", retriever_faiss, \"rag-zero-shot\"),\n",
        "    (\"Hybrid RAG\", ensemble_retriever, \"rag-few-shot\"),\n",
        "]\n",
        "\n",
        "# Modelos a evaluar\n",
        "models = {\n",
        "    \"GPT-3.5 Turbo\": model_gpt35,\n",
        "    \"Claude 3.5 Sonnet\": model_claude\n",
        "}\n",
        "\n",
        "results_all = {}\n",
        "\n",
        "# --- Evaluaci√≥n ---\n",
        "for model_name, model_obj in models.items():\n",
        "    print(f\"\\n================ {model_name} ================\\n\")\n",
        "\n",
        "    for strat_name, retriever_used, strategy_code in strategies:\n",
        "\n",
        "        exp_name = f\"{model_name} - {strat_name}\"\n",
        "        print(f\"Evaluando: {exp_name} ...\")\n",
        "\n",
        "        try:\n",
        "            system = GuaraniTransformationSystem(\n",
        "                llm=model_obj,\n",
        "                retriever=retriever_used,\n",
        "                strategy=strategy_code\n",
        "            )\n",
        "\n",
        "            # Evaluar\n",
        "            res = system.evaluate_dataset(dev_data)\n",
        "            results_all[exp_name] = res\n",
        "\n",
        "            # Accuracy\n",
        "            correct = sum(r[\"correct\"] for r in res)\n",
        "            total = len(res)\n",
        "            acc = (correct / total) * 100 if total > 0 else 0\n",
        "\n",
        "            print(f\"‚úì {exp_name}: {acc:.2f}% accuracy ({correct}/{total})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error en {exp_name}: {e}\")\n",
        "\n",
        "print(\"\\n‚úì Evaluaci√≥n completa\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b12ed2",
      "metadata": {
        "id": "52b12ed2"
      },
      "source": [
        "## 10. C√°lculo de M√©tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a21a87d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a21a87d3",
        "outputId": "e2baf578-3c4e-4b78-e631-0eb1a446bba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "RESULTADOS DE EVALUACI√ìN COMPLETA\n",
            "======================================================================\n",
            "\n",
            "GPT-3.5 Turbo - Zero-Shot:\n",
            "  Accuracy:   0.00%\n",
            "  BLEU Score: 59.46\n",
            "  Correctas:  0/10\n",
            "\n",
            "GPT-3.5 Turbo - Few-Shot:\n",
            "  Accuracy:   10.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  1/10\n",
            "\n",
            "GPT-3.5 Turbo - Semantic RAG:\n",
            "  Accuracy:   0.00%\n",
            "  BLEU Score: 59.46\n",
            "  Correctas:  0/10\n",
            "\n",
            "GPT-3.5 Turbo - Hybrid RAG:\n",
            "  Accuracy:   10.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  1/10\n",
            "\n",
            "Claude 3.5 Sonnet - Zero-Shot:\n",
            "  Accuracy:   30.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  3/10\n",
            "\n",
            "Claude 3.5 Sonnet - Few-Shot:\n",
            "  Accuracy:   50.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  5/10\n",
            "\n",
            "Claude 3.5 Sonnet - Semantic RAG:\n",
            "  Accuracy:   20.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  2/10\n",
            "\n",
            "Claude 3.5 Sonnet - Hybrid RAG:\n",
            "  Accuracy:   40.00%\n",
            "  BLEU Score: 0.00\n",
            "  Correctas:  4/10\n"
          ]
        }
      ],
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "def calculate_metrics(results: List[Dict]) -> Dict:\n",
        "    \"\"\"Calcula m√©tricas de evaluaci√≥n (Accuracy + BLEU) de forma robusta.\"\"\"\n",
        "\n",
        "    if not results:\n",
        "        return {\n",
        "            \"total\": 0,\n",
        "            \"correct\": 0,\n",
        "            \"accuracy\": 0.0,\n",
        "            \"bleu\": 0.0\n",
        "        }\n",
        "\n",
        "    total = len(results)\n",
        "    correct = sum(1 for r in results if r.get(\"correct\") is True)\n",
        "\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    for r in results:\n",
        "        pred = str(r.get(\"prediction\", \"\")).strip()\n",
        "        targ = str(r.get(\"target\", \"\")).strip()\n",
        "\n",
        "        # si est√° vac√≠o, ponemos un placeholder para evitar romper BLEU\n",
        "        if pred == \"\":\n",
        "            pred = \"<empty>\"\n",
        "        if targ == \"\":\n",
        "            targ = \"<empty>\"\n",
        "\n",
        "        preds.append(pred)\n",
        "        refs.append([targ])\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "\n",
        "    bleu = BLEU()\n",
        "    try:\n",
        "        bleu_score = bleu.corpus_score(preds, refs).score\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Error calculando BLEU:\", e)\n",
        "        bleu_score = 0.0\n",
        "\n",
        "    return {\n",
        "        \"total\": total,\n",
        "        \"correct\": correct,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"bleu\": bleu_score\n",
        "    }\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "#   CALCULAR M√âTRICAS PARA TODAS LAS CONFIGURACIONES\n",
        "# ===========================================================\n",
        "\n",
        "metrics_table = {}\n",
        "\n",
        "for name, results in results_all.items():\n",
        "    metrics_table[name] = calculate_metrics(results)\n",
        "\n",
        "# ===========================================================\n",
        "#   MOSTRAR RESULTADOS FORMATEADOS\n",
        "# ===========================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTADOS DE EVALUACI√ìN COMPLETA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for config, m in metrics_table.items():\n",
        "    print(f\"\\n{config}:\")\n",
        "    print(f\"  Accuracy:   {m['accuracy']:.2f}%\")\n",
        "    print(f\"  BLEU Score: {m['bleu']:.2f}\")\n",
        "    print(f\"  Correctas:  {m['correct']}/{m['total']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f411f7d",
      "metadata": {
        "id": "0f411f7d"
      },
      "source": [
        "## 11. Tabla Comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fff190af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fff190af",
        "outputId": "4a3b11ea-7409-457d-d6af-ff235f110ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TABLA COMPARATIVA COMPLETA\n",
            "======================================================================\n",
            "           Modelo   Estrategia  Accuracy (%)  BLEU  Correctas  Total\n",
            "    GPT-3.5 Turbo    Zero-Shot           0.0 59.46          0     10\n",
            "    GPT-3.5 Turbo     Few-Shot          10.0  0.00          1     10\n",
            "    GPT-3.5 Turbo Semantic RAG           0.0 59.46          0     10\n",
            "    GPT-3.5 Turbo   Hybrid RAG          10.0  0.00          1     10\n",
            "Claude 3.5 Sonnet    Zero-Shot          30.0  0.00          3     10\n",
            "Claude 3.5 Sonnet     Few-Shot          50.0  0.00          5     10\n",
            "Claude 3.5 Sonnet Semantic RAG          20.0  0.00          2     10\n",
            "Claude 3.5 Sonnet   Hybrid RAG          40.0  0.00          4     10\n",
            "\n",
            "======================================================================\n",
            "MEJOR CONFIGURACI√ìN (por Accuracy)\n",
            "======================================================================\n",
            "Modelo: Claude 3.5 Sonnet\n",
            "Estrategia: Few-Shot\n",
            "Accuracy: 50.00%\n",
            "BLEU: 0.00\n"
          ]
        }
      ],
      "source": [
        "# Convertir diccionario de m√©tricas (metrics_table) a DataFrame\n",
        "rows = []\n",
        "\n",
        "for config, m in metrics_table.items():\n",
        "    # Separar nombre del modelo y estrategia\n",
        "    parts = config.split(\" - \", 1)\n",
        "    modelo = parts[0]\n",
        "    estrategia = parts[1] if len(parts) > 1 else \"Desconocida\"\n",
        "\n",
        "    rows.append({\n",
        "        \"Modelo\": modelo,\n",
        "        \"Estrategia\": estrategia,\n",
        "        \"Accuracy (%)\": round(m.get(\"accuracy\", 0), 2),\n",
        "        \"BLEU\": round(m.get(\"bleu\", 0), 2),\n",
        "        \"Correctas\": m.get(\"correct\", 0),\n",
        "        \"Total\": m.get(\"total\", 0)\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TABLA COMPARATIVA COMPLETA\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "\n",
        "# ==============================\n",
        "#  MEJOR MODELO POR ACCURACY\n",
        "# ==============================\n",
        "\n",
        "if comparison_df[\"Accuracy (%)\"].max() > 0:\n",
        "    best_idx = comparison_df[\"Accuracy (%)\"].idxmax()\n",
        "    best_row = comparison_df.iloc[best_idx]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MEJOR CONFIGURACI√ìN (por Accuracy)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Modelo: {best_row['Modelo']}\")\n",
        "    print(f\"Estrategia: {best_row['Estrategia']}\")\n",
        "    print(f\"Accuracy: {best_row['Accuracy (%)']:.2f}%\")\n",
        "    print(f\"BLEU: {best_row['BLEU']:.2f}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Ning√∫n modelo obtuvo accuracy > 0. Revisa los prompts o el conjunto de prueba.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68af82e7",
      "metadata": {
        "id": "68af82e7"
      },
      "source": [
        "## 12. Ejemplos de Transformaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f0863e4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0863e4f",
        "outputId": "e3b29f0c-c9ea-4175-a305-f12aff1c5b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EJEMPLOS DE TRANSFORMACIONES (GPT-3.5 Turbo - Semantic RAG)\n",
            "======================================================================\n",
            "\n",
            "Ejemplo 1:\n",
            "  ID: Guarani0232\n",
            "  Oraci√≥n original: Ore ndorombyai kuri\n",
            "  Transformaci√≥n: TYPE:AFF\n",
            "  Esperado: Ore rombyai kuri\n",
            "  Generado: Ore rombyai kuri.\n",
            "  ‚úó Incorrecto\n",
            "\n",
            "Ejemplo 2:\n",
            "  ID: Guarani0233\n",
            "  Oraci√≥n original: Ore ndorombyai kuri\n",
            "  Transformaci√≥n: TENSE:FUT_SIM\n",
            "  Esperado: Ore ndorombyaita\n",
            "  Generado: Ore ndorombyaikuri ta.\n",
            "  ‚úó Incorrecto\n",
            "\n",
            "Ejemplo 3:\n",
            "  ID: Guarani0234\n",
            "  Oraci√≥n original: Ore ndorombyai kuri\n",
            "  Transformaci√≥n: PERSON:1_PL_INC\n",
            "  Esperado: √ëande na√±ambyai kuri\n",
            "  Generado: Ore ndorombyai kuri.\n",
            "  ‚úó Incorrecto\n",
            "\n",
            "Ejemplo 4:\n",
            "  ID: Guarani0235\n",
            "  Oraci√≥n original: Ore ndorombyai kuri\n",
            "  Transformaci√≥n: PERSON:1_SI\n",
            "  Esperado: Che nambyai kuri\n",
            "  Generado: Ndo ore ndorombyai kuri.\n",
            "  ‚úó Incorrecto\n",
            "\n",
            "Ejemplo 5:\n",
            "  ID: Guarani0236\n",
            "  Oraci√≥n original: Ore ndorombyai kuri\n",
            "  Transformaci√≥n: PERSON:2_PL\n",
            "  Esperado: Pe·∫Ω napembyai kuri\n",
            "  Generado: Ore ndorombyai kuri.\n",
            "  ‚úó Incorrecto\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EJEMPLOS DE TRANSFORMACIONES (GPT-3.5 Turbo - Semantic RAG)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Extraer resultados desde el diccionario general\n",
        "results_gpt_rag = results_all.get(\"GPT-3.5 Turbo - Semantic RAG\", [])\n",
        "\n",
        "if not results_gpt_rag:\n",
        "    print(\" No hay resultados para GPT-3.5 Turbo - Semantic RAG\")\n",
        "else:\n",
        "    for i, result in enumerate(results_gpt_rag[:5], 1):\n",
        "        print(f\"\\nEjemplo {i}:\")\n",
        "        print(f\"  ID: {result['id']}\")\n",
        "        print(f\"  Oraci√≥n original: {result['source']}\")\n",
        "        print(f\"  Transformaci√≥n: {result['change']}\")\n",
        "        print(f\"  Esperado: {result['target']}\")\n",
        "        print(f\"  Generado: {result['prediction']}\")\n",
        "        print(f\"  ‚úì Correcto\" if result['correct'] else \"  ‚úó Incorrecto\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba05dec",
      "metadata": {
        "id": "bba05dec"
      },
      "source": [
        "## 13. Exportar Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4d6cb53e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "4d6cb53e",
        "outputId": "4a48ff72-075d-4960-fb8d-b1d778e6d6d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guardando resultados...\n",
            "‚úì Resultados guardados en: guarani_transformation_results.json\n",
            "‚úì Tabla comparativa guardada: comparison_table.csv\n",
            "‚úì Vector store FAISS guardado en carpeta: faiss_store\n",
            "‚úì Vector store comprimido en ZIP: faiss_store.zip\n",
            "‚úì Documentos del RAG guardados: rag_documents.json\n",
            "‚úì Metadata adicional guardada: rag_metadata.json\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_fcec863e-6483-45d3-ab55-27bb59fcc4a9\", \"guarani_transformation_results.json\", 20628)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1da11dd0-831e-46ab-becd-d20f4b670cb6\", \"comparison_table.csv\", 380)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ea02aef9-205b-4d9b-af95-30a1e210d790\", \"rag_documents.json\", 987447)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_efa851ce-8068-4f39-9d88-6341dc578915\", \"rag_metadata.json\", 177)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1cbbe3fc-5694-4912-93e8-e847d3c7a642\", \"faiss_store.zip\", 457457)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Descarga completada\n"
          ]
        }
      ],
      "source": [
        "print(\"Guardando resultados...\")\n",
        "\n",
        "# ================================\n",
        "# 1) REORGANIZAR RESULTADOS\n",
        "# ================================\n",
        "all_results = {\n",
        "    \"results\": results_all,      # todas las ejecuciones\n",
        "    \"metrics\": metrics_table,    # m√©tricas de accuracy y BLEU\n",
        "    \"metadata\": {\n",
        "        \"dataset\": \"AmericasNLP 2025 - Guaran√≠\",\n",
        "        \"models_tested\": [\n",
        "            \"openai/gpt-3.5-turbo\",\n",
        "            \"anthropic/claude-3.5-sonnet\"\n",
        "        ],\n",
        "        \"strategies\": [\n",
        "            \"Zero-Shot\",\n",
        "            \"Few-Shot\",\n",
        "            \"Semantic RAG\",\n",
        "            \"Hybrid RAG\"\n",
        "        ],\n",
        "        \"embedding_model\": \"E5 embedding ONNX (custom wrapper)\",\n",
        "        \"vector_store\": \"FAISS + BM25 + Ensemble\",\n",
        "        \"sources_used\": [\n",
        "            \"Gram√°tica guaran√≠.pdf\",\n",
        "            \"Diccionario Guaran√≠-Espa√±ol / Espa√±ol-Guaran√≠.pdf\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# ================================\n",
        "# 2) GUARDAR JSON DE RESULTADOS\n",
        "# ================================\n",
        "with open(\"guarani_transformation_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úì Resultados guardados en: guarani_transformation_results.json\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3) EXPORTAR TABLA COMPARATIVA\n",
        "# ================================\n",
        "comparison_df.to_csv(\"comparison_table.csv\", index=False)\n",
        "print(\"‚úì Tabla comparativa guardada: comparison_table.csv\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4) EXPORTAR VECTOR STORE (FAISS) + ZIP\n",
        "# ================================\n",
        "FAISS_DIR = \"faiss_store\"\n",
        "\n",
        "import os\n",
        "os.makedirs(FAISS_DIR, exist_ok=True)\n",
        "\n",
        "# Guardado en carpeta\n",
        "vectorstore.save_local(FAISS_DIR)\n",
        "print(f\"‚úì Vector store FAISS guardado en carpeta: {FAISS_DIR}\")\n",
        "\n",
        "# Comprimir carpeta a ZIP\n",
        "zip_name = \"faiss_store.zip\"\n",
        "!zip -r {zip_name} {FAISS_DIR} > /dev/null\n",
        "\n",
        "print(f\"‚úì Vector store comprimido en ZIP: {zip_name}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5) EXPORTAR DOCUMENTOS RAG\n",
        "# ================================\n",
        "docs_export = [d.page_content for d in documents]\n",
        "\n",
        "with open(\"rag_documents.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(docs_export, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úì Documentos del RAG guardados: rag_documents.json\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6) EXPORTAR METADATA ADICIONAL\n",
        "# ================================\n",
        "metadata_extra = {\n",
        "    \"faiss_zip\": zip_name,\n",
        "    \"embedding_model\": \"E5-ONNX custom wrapper\",\n",
        "    \"num_documents\": len(documents),\n",
        "    \"chunks_info\": {\n",
        "        \"min_length\": min(len(d.page_content) for d in documents),\n",
        "        \"max_length\": max(len(d.page_content) for d in documents)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"rag_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metadata_extra, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úì Metadata adicional guardada: rag_metadata.json\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7) DESCARGA AUTOM√ÅTICA (COLAB)\n",
        "# ================================\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    files.download(\"guarani_transformation_results.json\")\n",
        "    files.download(\"comparison_table.csv\")\n",
        "    files.download(\"rag_documents.json\")\n",
        "    files.download(\"rag_metadata.json\")\n",
        "    files.download(zip_name)  # <-- ZIP DEL VECTOR STORE\n",
        "\n",
        "    print(\"‚úì Descarga completada\")\n",
        "except Exception as e:\n",
        "    print(\"Descarga no disponible:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e309bd28",
      "metadata": {
        "id": "e309bd28"
      },
      "source": [
        "# Resultados y An√°lisis Comparativo ‚Äì Transformaciones en Guaran√≠\n",
        "---\n",
        "\n",
        "## Modelos evaluados\n",
        "- **GPT-3.5 Turbo** (OpenAI)\n",
        "- **Claude 3.5 Sonnet** (Anthropic)\n",
        "\n",
        "## Estrategias comparadas\n",
        "1. **Zero-Shot**\n",
        "2. **Few-Shot**\n",
        "3. **Semantic RAG** (FAISS)\n",
        "4. **Hybrid RAG** (BM25 + FAISS + Few-Shot)\n",
        "\n",
        "---\n",
        "\n",
        "# Resultados Obtenidos\n",
        "\n",
        "| Modelo              | Estrategia      | Accuracy (%) | BLEU  | Correctas / Total |\n",
        "|---------------------|-----------------|--------------|-------|-------------------|\n",
        "| GPT-3.5 Turbo       | Zero-Shot       | 0.0          | 59.46 | 0/10              |\n",
        "| GPT-3.5 Turbo       | Few-Shot        | 10.0         | 0.00  | 1/10              |\n",
        "| GPT-3.5 Turbo       | Semantic RAG    | 0.0          | 59.46 | 0/10              |\n",
        "| GPT-3.5 Turbo       | Hybrid RAG      | 10.0         | 0.00  | 1/10              |\n",
        "| Claude 3.5 Sonnet   | Zero-Shot       | 30.0         | 0.00  | 3/10              |\n",
        "| Claude 3.5 Sonnet   | Few-Shot        | 50.0         | 0.00  | 5/10              |\n",
        "| Claude 3.5 Sonnet   | Semantic RAG    | 20.0         | 0.00  | 2/10              |\n",
        "| Claude 3.5 Sonnet   | Hybrid RAG      | 40.0         | 0.00  | 4/10              |\n",
        "\n",
        "---\n",
        "\n",
        "# Mejor Configuraci√≥n\n",
        "\n",
        "- **Modelo ganador:** Claude 3.5 Sonnet  \n",
        "- **Mejor estrategia:** Few-Shot  \n",
        "- **Accuracy m√°ximo:** **50%**\n",
        "\n",
        "---\n",
        "\n",
        "# An√°lisis del Desempe√±o\n",
        "\n",
        "### 1. Claude 3.5 Sonnet supera ampliamente a GPT-3.5 Turbo\n",
        "Claude demuestra mejores capacidades para comprender y aplicar transformaciones morfol√≥gicas en guaran√≠.\n",
        "\n",
        "### 2. La estrategia **Few-Shot** es la m√°s efectiva\n",
        "Agregar ejemplos reales del dataset mejora la capacidad del modelo para seguir patrones ling√º√≠sticos.\n",
        "\n",
        "### 3. **RAG NO mejora el rendimiento**\n",
        "El contexto recuperado desde la Gram√°tica Guaran√≠ y el Diccionario:\n",
        "- No contiene transformaciones expl√≠citas **Source ‚Üí Target**  \n",
        "- Aporta descripciones te√≥ricas, no reglas aplicables  \n",
        "- Los chunks son demasiado generales para guiar al LLM  \n",
        "- Introduce ruido y aumenta la incertidumbre del modelo  \n",
        "\n",
        "Por eso, las variantes **Semantic RAG** y **Hybrid RAG** no superan al Few-Shot.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "- **Few-Shot > Zero-Shot > RAG**, seg√∫n nuestros resultados.  \n",
        "- RAG no ofrece beneficios para este caso porque el conocimiento recuperado no ayuda a realizar transformaciones espec√≠ficas del dataset.  \n",
        "- Para mejorar significativamente el rendimiento, el siguiente paso debe ser:  \n",
        "  **Fine-Tuning supervisado (SFT)** utilizando el *train set* completo.\n",
        "\n",
        "---\n",
        "\n",
        "# Archivos generados\n",
        "- `guarani_transformation_results.json`\n",
        "- `comparison_table.csv`\n",
        "- Este archivo: `analysis_results.md`\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
