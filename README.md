# ğŸ‡µğŸ‡¾ Sistema de TransformaciÃ³n de Oraciones en GuaranÃ­

Sistema de PLN que transforma oraciones en guaranÃ­ segÃºn reglas gramaticales, comparando GPT-3.5 Turbo vs Claude 3.5 Sonnet con 4 estrategias (Zero-Shot, Few-Shot, Semantic RAG, Hybrid RAG).

**Dataset:** AmericasNLP 2025 - Educational Materials Transformation  
**Tarea:** Transformar oraciones en guaranÃ­ segÃºn reglas morfolÃ³gicas especÃ­ficas

---

## ğŸ“‹ DescripciÃ³n del Proyecto

### Objetivo
Comparar el rendimiento de **LLMs con prompting (sin RAG)** vs **Agentes con RAG** para transformar oraciones en guaranÃ­ segÃºn reglas gramaticales especÃ­ficas.

### DesafÃ­o
El guaranÃ­ es una **lengua de bajos recursos** con:
- Escasez de datos lingÃ¼Ã­sticos anotados
- VariaciÃ³n dialectal y ortogrÃ¡fica (JoparÃ¡ - mezcla guaranÃ­-espaÃ±ol)
- Poca representaciÃ³n en modelos de lenguaje pre-entrenados

### MetodologÃ­a
1. **Dataset:** AmericasNLP 2025 (train/dev/test splits)
2. **Base de conocimiento RAG:**
   - GramÃ¡tica GuaranÃ­ (EdiciÃ³n 2020) - 200+ pÃ¡ginas
   - Diccionario GuaranÃ­-EspaÃ±ol / EspaÃ±ol-GuaranÃ­
   - 1400+ chunks indexados en FAISS
3. **Modelos evaluados:**
   - GPT-3.5 Turbo (OpenAI)
   - Claude 3.5 Sonnet (Anthropic)
4. **Estrategias comparadas:**
   - Zero-Shot (sin ejemplos)
   - Few-Shot (con ejemplos)
   - Semantic RAG (FAISS)
   - Hybrid RAG (BM25 + FAISS + Few-Shot)
5. **MÃ©tricas:** Accuracy (exact match) y BLEU Score

---

## ğŸ“Š Resultados

| Modelo | Estrategia | Accuracy | Correctas |
|--------|------------|----------|-----------|
| GPT-3.5 Turbo | Zero-Shot | 0% | 0/10 |
| GPT-3.5 Turbo | Few-Shot | 10% | 1/10 |
| GPT-3.5 Turbo | Semantic RAG | 0% | 0/10 |
| GPT-3.5 Turbo | Hybrid RAG | 10% | 1/10 |
| Claude 3.5 Sonnet | Zero-Shot | 30% | 3/10 |
| **Claude 3.5 Sonnet** | **Few-Shot** | **ğŸ† 50%** | **5/10** |
| Claude 3.5 Sonnet | Semantic RAG | 20% | 2/10 |
| Claude 3.5 Sonnet | Hybrid RAG | 40% | 4/10 |

**ğŸ† Mejor configuraciÃ³n:** Claude 3.5 Sonnet + Few-Shot (50% accuracy)

### InterpretaciÃ³n de Resultados

**Â¿Por quÃ© Claude es mejor que GPT-3.5?**
- Mayor capacidad de comprensiÃ³n morfolÃ³gica
- Mejor seguimiento de instrucciones en guaranÃ­
- MÃ¡s consistente en todas las estrategias

**Â¿Por quÃ© Few-Shot supera a RAG?**
- Los ejemplos directos son mÃ¡s relevantes que la teorÃ­a gramatical
- La gramÃ¡tica contiene descripciones abstractas, no transformaciones prÃ¡cticas
- Los chunks recuperados son demasiado genÃ©ricos para guiar al modelo

---

## ğŸ“š Base de Conocimiento (RAG)

### Documentos Utilizados
1. **GramÃ¡tica GuaranÃ­ 2020** (Academia de la Lengua GuaranÃ­)
   - 200+ pÃ¡ginas de teorÃ­a gramatical
   - Reglas de morfologÃ­a, sintaxis y fonÃ©tica
   
2. **Diccionario GuaranÃ­-EspaÃ±ol / EspaÃ±ol-GuaranÃ­**
   - Vocabulario bilingÃ¼e
   - Traducciones y ejemplos de uso

### Proceso de ConstrucciÃ³n del Vector Store
```
PDF â†’ ExtracciÃ³n de texto â†’ Limpieza â†’ Chunking â†’ Embeddings â†’ FAISS
```

**ParÃ¡metros:**
- Chunk size: 650 caracteres
- Overlap: 120 caracteres
- Total chunks: 1400+
- Embedding: Hash-based (SHA-256, 384 dims)
- Vector store: FAISS + BM25 (Hybrid)

---

## ğŸ§ª Experimentos Realizados

### 1. ComparaciÃ³n de Modelos (GPT-3.5 vs Claude 3.5)
Evaluamos ambos modelos en las 4 estrategias usando 10 ejemplos del dev set.

### 2. ComparaciÃ³n de Estrategias
- **Zero-Shot:** Solo instrucciones, sin ejemplos ni contexto
- **Few-Shot:** 3 ejemplos de transformaciones en el prompt
- **Semantic RAG:** RecuperaciÃ³n de 3 chunks relevantes con FAISS
- **Hybrid RAG:** BM25 (60%) + FAISS (40%) + Few-Shot

### 3. Tipos de Transformaciones Evaluadas
- `TYPE:AFF` - Negativa â†’ Afirmativa (remover ndo-...-i)
- `TYPE:NEG` - Afirmativa â†’ Negativa (agregar ndo-...-i)
- `TENSE:FUT_SIM` - Agregar marcador futuro (-ta)
- `TENSE:PAST` - Agregar marcador pasado (kuri)
- `PERSON:1_PL_INC` - 1Âª persona plural inclusiva (Ã±ande)
- `PERSON:1_PL_EXC` - 1Âª persona plural exclusiva (ore)
- `PERSON:3` - 3Âª persona singular (ha'e)

### 4. Notebook Completo
Todos los experimentos estÃ¡n documentados en `projectIA.ipynb` que incluye:
- CÃ³digo de construcciÃ³n del RAG
- ImplementaciÃ³n de las 4 estrategias
- EvaluaciÃ³n de ambos modelos
- CÃ¡lculo de mÃ©tricas (Accuracy, BLEU)
- AnÃ¡lisis de resultados

**Ejecutar en Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JuanAquino22/project_ia/blob/main/projectIA.ipynb)

---

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos
- Python 3.11+
- Docker (opcional)
- API Key de OpenRouter

### ConfiguraciÃ³n RÃ¡pida

```bash
# Clonar repositorio
git clone https://github.com/JuanAquino22/project_ia.git
cd project_ia

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar API key
cp .env.example .env
# Editar .env y agregar tu OPENROUTER_API_KEY
```

### Ejecutar

**OpciÃ³n A - Local:**
```bash
python app.py
# Abrir: http://localhost:7860
```

**OpciÃ³n B - Docker:**
```bash
docker-compose up --build
# Abrir: http://localhost:7860
```

---

## ğŸ“ Estructura del Proyecto

```
project_ia/
â”œâ”€â”€ app.py                              # AplicaciÃ³n Gradio
â”œâ”€â”€ projectIA.ipynb                     # Notebook con experimentos
â”œâ”€â”€ finetuning_guarani.ipynb           # Fine-tuning BLOOM-560M + LoRA
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ faiss_store/                        # Vector store (1400 chunks)
â”œâ”€â”€ guarani_transformation_results.json # Resultados detallados
â””â”€â”€ comparison_table.csv                # Tabla resumen
```
---

## ğŸ“ Ejemplo de TransformaciÃ³n

**Input:**
```
OraciÃ³n: "Ore ndorombyai kuri"
Regla: TYPE:AFF (convertir a afirmativo)
```

**Output esperado:**
```
"Ore rombyai kuri"
```

**Resultados por estrategia:**
- âœ… Claude Few-Shot: "Ore rombyai kuri" (correcto)
- âœ… GPT-3.5 Few-Shot: "Ore rombyai kuri" (1/10 correctas)
- âŒ Claude Zero-Shot: "Ore rombyai" (incompleto)

---

## ğŸ” Conclusiones Principales

### 1. Claude 3.5 Sonnet > GPT-3.5 Turbo
- **Accuracy:** 50% vs 10% (5x mejor)
- **Consistencia:** Mejores resultados en todas las estrategias
- **ComprensiÃ³n morfolÃ³gica:** Superior manejo de reglas guaranÃ­es

### 2. Few-Shot > RAG
- **Few-Shot:** 50% accuracy (mejor)
- **Hybrid RAG:** 40%
- **Zero-Shot:** 30%
- **Semantic RAG:** 20% (peor)

**ğŸ”‘ Hallazgo crÃ­tico:** RAG con gramÃ¡tica teÃ³rica NO mejora el rendimiento. Los ejemplos directos (Few-Shot) son mÃ¡s efectivos.

### 3. Â¿Por quÃ© RAG no funcionÃ³?
- GramÃ¡tica contiene **teorÃ­a abstracta**, no **transformaciones prÃ¡cticas**
- Chunks recuperados son demasiado genÃ©ricos
- Contexto adicional confunde al modelo
- Few-Shot directo proporciona ejemplos mÃ¡s relevantes

**ImplicaciÃ³n para lenguas de bajo recurso:**
- RAG es Ãºtil SOLO si la base de conocimiento contiene ejemplos prÃ¡cticos
- Para lenguas indÃ­genas, priorizar few-shot learning con ejemplos reales
- La calidad del corpus importa mÃ¡s que la tÃ©cnica de recuperaciÃ³n

---

## ğŸ¯ Hallazgos Principales

### 1. ComparaciÃ³n Sin RAG vs Con RAG

| Enfoque | Mejor Accuracy | Modelo |
|---------|----------------|--------|
| **Sin RAG (Few-Shot)** | **50%** | Claude 3.5 Sonnet |
| Con RAG (Hybrid) | 40% | Claude 3.5 Sonnet |
| Con RAG (Semantic) | 20% | Claude 3.5 Sonnet |

**ConclusiÃ³n:** Para esta tarea, **Few-Shot supera a RAG** porque:
- Los ejemplos directos son mÃ¡s especÃ­ficos que la teorÃ­a gramatical
- RAG no aporta informaciÃ³n Ãºtil para transformaciones morfolÃ³gicas exactas

### 2. Lecciones Aprendidas

**âœ… Lo que funcionÃ³:**
- Claude 3.5 Sonnet > GPT-3.5 en morfologÃ­a guaranÃ­
- Few-Shot con ejemplos reales del dataset
- Temperatura baja (0.2) para salidas determinÃ­sticas

**âŒ Lo que NO funcionÃ³:**
- RAG con gramÃ¡tica teÃ³rica (sin ejemplos prÃ¡cticos)
- Zero-Shot (modelos sin conocimiento previo de guaranÃ­)
- GPT-3.5 (rendimiento muy bajo: 0-10%)

### 3. Recomendaciones para Mejorar

**A corto plazo:**
- Usar Claude 3.5 Sonnet con Few-Shot (configuraciÃ³n Ã³ptima actual)
- Aumentar ejemplos few-shot del train set completo

**A mediano plazo:**
- **Fine-tuning supervisado (SFT)** con BLOOM-560M o similar (ver `finetuning_guarani.ipynb`)
- Crear base de conocimiento con transformaciones reales (no teorÃ­a)

---

## ğŸ“Š Archivos Generados

- `guarani_transformation_results.json` - Resultados completos de evaluaciÃ³n
- `comparison_table.csv` - Tabla resumen con mÃ©tricas
- `faiss_store/` - Vector store con gramÃ¡tica indexada
- `rag_documents.json` - 1400+ chunks del corpus
- `rag_metadata.json` - Metadatos del RAG

---

## ğŸ“š TecnologÃ­as

- **LLMs:** OpenRouter API (GPT-3.5 Turbo, Claude 3.5 Sonnet)
- **RAG:** LangChain + FAISS + BM25
- **Embeddings:** Hash-based (SHA-256, custom)
- **Interfaz:** Gradio 3.50.2
- **MÃ©tricas:** SacreBLEU
- **Dataset:** AmericasNLP 2025 - GuaranÃ­

---

## ğŸ“– Referencias

- [AmericasNLP 2025 - Shared Task 2](https://github.com/AmericasNLP/americasnlp2025/tree/main/ST2_EducationalMaterials)
- GramÃ¡tica GuaranÃ­ (Academia de la Lengua GuaranÃ­, 2020)
- [OpenRouter API](https://openrouter.ai/)
- [LangChain Documentation](https://python.langchain.com/)

---

## ğŸ‘¤ Autor

**Juan Aquino**  
Proyecto Final - Diplomado en Procesamiento de Lenguaje Natural e Inteligencia Artificial  
Facultad PolitÃ©cnica, Universidad Nacional de AsunciÃ³n (FPUNA)  
Diciembre 2025

---

## ğŸ“„ Licencia

Proyecto educativo desarrollado para el Diplomado en PLN e IA - FPUNA 2025  
Dataset: [AmericasNLP 2025](https://github.com/AmericasNLP/americasnlp2025) (licencia del dataset original)

---

## ğŸ‡µğŸ‡¾ Sobre el GuaranÃ­

El guaranÃ­ es una lengua indÃ­gena hablada por mÃ¡s de 6 millones de personas en Paraguay, Argentina, Bolivia y Brasil. Es idioma oficial de Paraguay junto al espaÃ±ol. Este proyecto busca contribuir al desarrollo de herramientas de PLN para lenguas de bajo recurso.

**Mba'Ã©ichapa!** ğŸ‡µğŸ‡¾
