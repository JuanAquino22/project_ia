# ğŸ‡µğŸ‡¾ Sistema de TransformaciÃ³n de Oraciones en GuaranÃ­ con RAG

Sistema de procesamiento de lenguaje natural para transformar oraciones en guaranÃ­ segÃºn reglas gramaticales especÃ­ficas, comparando el rendimiento de modelos de lenguaje con y sin **RAG (Retrieval-Augmented Generation)**.

---

## ğŸ“– Â¿QuÃ© hace este sistema?

Este proyecto implementa un sistema capaz de transformar oraciones en guaranÃ­ aplicando reglas gramaticales especÃ­ficas (negaciÃ³n â†’ afirmaciÃ³n, tiempo verbal, etc.).

**Objetivo principal:** Evaluar si el uso de RAG (recuperaciÃ³n de documentaciÃ³n gramatical) mejora la capacidad de los LLMs para generar transformaciones correctas en **idiomas de bajo recursos** como el guaranÃ­.

### Dataset: AmericasNLP 2025

Utilizamos el dataset oficial de AmericasNLP para la tarea de transformaciÃ³n educativa:
- **Input:** OraciÃ³n base (`Source`) + Regla de transformaciÃ³n (`Change`)
- **Output:** OraciÃ³n transformada (`Target`)

**Ejemplo:**
```
Source: "Ore ndorombyai kuri"
Change: "TYPE:AFF" (convertir a afirmativo)
Target: "Ore rombyai kuri"
```

### Â¿Por quÃ© GuaranÃ­?

El guaranÃ­ es un **idioma de bajo recursos** en PLN, lo que significa que los modelos de lenguaje tienen conocimiento limitado sobre Ã©l. Este proyecto demuestra cÃ³mo RAG puede mejorar el rendimiento de los LLMs en estas lenguas.

---

## ğŸ› ï¸ MetodologÃ­a

### 1. Dataset y Tarea

**Dataset:** AmericasNLP 2025 - Educational Materials Transformation
- **Train:** Para ajuste de prompts y experimentaciÃ³n
- **Dev:** Para validaciÃ³n y ajuste de hiperparÃ¡metros
- **Test:** Para evaluaciÃ³n final

**Splits:**
```
â”œâ”€â”€ guarani-train.tsv
â”œâ”€â”€ guarani-dev.tsv
â””â”€â”€ guarani-test.tsv
```

### 2. Base de Conocimiento (RAG)

**Documentos utilizados:**
- `GramÃ¡tica guaranÃ­.pdf` (EdiciÃ³n 2020)
- `Diccionario GuaranÃ­-EspaÃ±ol.pdf` (opcional)

**Proceso de construcciÃ³n:**
```
PDF â†’ ExtracciÃ³n de texto â†’ Chunking (1000 chars) â†’ Embeddings â†’ FAISS Vector Store
```

| ParÃ¡metro | Valor |
|-----------|-------|
| Modelo de embeddings | `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` |
| TamaÃ±o de chunk | 1000 caracteres |
| Overlap entre chunks | 200 caracteres |
| Vector Store | FAISS |
| Documentos recuperados (k) | 3 |

### 3. Modelos Evaluados

| Modelo | Proveedor | CaracterÃ­sticas |
|--------|-----------|-----------------|
| **GPT-3.5 Turbo** | OpenAI | RÃ¡pido, econÃ³mico |
| **Claude 3.5 Sonnet** | Anthropic | MÃ¡s potente, respuestas detalladas |

### 4. Estrategias Comparadas

| Estrategia | DescripciÃ³n |
|------------|-------------|
| **Sin RAG** | El modelo usa solo su conocimiento previo del guaranÃ­ |
| **Con RAG** | El modelo recibe fragmentos relevantes de la gramÃ¡tica guaranÃ­ |

---

## ğŸ“Š Resultados Completos

### MÃ©tricas Evaluadas

- **Accuracy:** Porcentaje de transformaciones exactamente correctas
- **BLEU Score:** Similitud entre la transformaciÃ³n generada y la esperada
- **Correctas/Total:** NÃºmero de transformaciones correctas sobre el total evaluado

### Tabla Comparativa - EvaluaciÃ³n sobre 10 ejemplos (Dev Set)

| Modelo | Estrategia | Accuracy (%) | BLEU | Correctas | Total |
|--------|------------|--------------|------|-----------|-------|
| GPT-3.5 Turbo | Zero-Shot | 0.0% | 59.46 | 0/10 | âŒ |
| GPT-3.5 Turbo | Few-Shot | **10.0%** | 0.0 | 1/10 | âš ï¸ |
| GPT-3.5 Turbo | Semantic RAG | 0.0% | 59.46 | 0/10 | âŒ |
| GPT-3.5 Turbo | Hybrid RAG | **10.0%** | 0.0 | 1/10 | âš ï¸ |
| Claude 3.5 Sonnet | Zero-Shot | 30.0% | 0.0 | 3/10 | ğŸŸ¡ |
| Claude 3.5 Sonnet | **Few-Shot** | **50.0%** | 0.0 | **5/10** | âœ… **MEJOR** |
| Claude 3.5 Sonnet | Semantic RAG | 20.0% | 0.0 | 2/10 | ğŸŸ¡ |
| Claude 3.5 Sonnet | Hybrid RAG | 40.0% | 0.0 | 4/10 | ğŸŸ¢ |

### ğŸ† Mejor ConfiguraciÃ³n

**Modelo ganador:** Claude 3.5 Sonnet  
**Estrategia Ã³ptima:** Few-Shot  
**Accuracy alcanzado:** 50.0% (5 de 10 correctas)

---

### Ejemplo de TransformaciÃ³n Real

**Input:**
```
Source: "Ore ndorombyai kuri"
Change: "TYPE:AFF" (convertir negativa a afirmativa)
Target esperado: "Ore rombyai kuri"
```

**Claude 3.5 Sonnet (Few-Shot):**
```
Prediction: "Ore rombyai kuri" âœ… CORRECTO
```

**GPT-3.5 Turbo (Few-Shot):**
```
Prediction: "Ore rombyai kuri" âœ… CORRECTO (1 de 10 total)
```

**Claude 3.5 Sonnet (Zero-Shot):**
```
Prediction: "Ore rombyai" âŒ (incompleto, 3 de 10 total)
```

---

## ğŸ“ˆ Conclusiones y AnÃ¡lisis

### 1. ğŸ¥‡ Claude 3.5 Sonnet supera ampliamente a GPT-3.5 Turbo

**Claude 3.5 Sonnet** demostrÃ³ ser significativamente superior:
- **Mejor accuracy:** 50% vs 10% (5x mejor que GPT-3.5)
- **MÃ¡s consistente:** Todas las estrategias con Claude obtienen resultados superiores
- **Mejor comprensiÃ³n morfolÃ³gica:** Capaz de aplicar transformaciones gramaticales complejas en guaranÃ­

### 2. ğŸ¯ Few-Shot es la estrategia mÃ¡s efectiva

**Few-Shot obtuvo el mejor rendimiento:**
- **Claude + Few-Shot:** 50% accuracy (mejor configuraciÃ³n)
- **Claude + Hybrid RAG:** 40% accuracy
- **Claude + Zero-Shot:** 30% accuracy
- **Claude + Semantic RAG:** 20% accuracy

**ConclusiÃ³n:** Proporcionar ejemplos concretos mejora dramÃ¡ticamente el rendimiento.

### 3. âš ï¸ RAG NO mejorÃ³ el rendimiento (hallazgo crÃ­tico)

**Resultados contraintuitivos:**
- Few-Shot simple (50%) > Hybrid RAG (40%) > Semantic RAG (20%)
- RAG incluso empeorÃ³ el rendimiento comparado con Zero-Shot puro

**Â¿Por quÃ© RAG no funcionÃ³?**

1. **Contexto inadecuado:** La GramÃ¡tica GuaranÃ­ contiene descripciones teÃ³ricas, NO transformaciones prÃ¡cticas Sourceâ†’Target
2. **Chunks genÃ©ricos:** Los fragmentos recuperados son demasiado amplios para guiar transformaciones especÃ­ficas
3. **Ruido contextual:** El contexto extra confunde al modelo en lugar de ayudarlo
4. **Dataset especÃ­fico:** Las transformaciones requieren patrones exactos que el RAG no captura

### 4. ğŸ“Š InterpretaciÃ³n del BLEU Score

**Nota importante sobre BLEU:**
- GPT-3.5 Zero-Shot: BLEU 59.46 pero 0% accuracy
- Claude Few-Shot: BLEU 0.0 pero 50% accuracy

**Â¿Por quÃ© esta discrepancia?**
- BLEU mide similitud parcial (n-gramas)
- Accuracy mide coincidencia exacta (mÃ¡s estricta)
- Para transformaciones gramaticales, accuracy es mÃ¡s relevante

### 5. ğŸ” AnÃ¡lisis por Tipo de TransformaciÃ³n

**Transformaciones mÃ¡s difÃ­ciles:**
- `TYPE:NEG` / `TYPE:AFF`: Requiere entender morfologÃ­a de negaciÃ³n (ndo-...-i)
- `PERSON:X`: Cambios de persona (ore/Ã±ande/ha'e)
- `TENSE:PAST` / `TENSE:FUT_SIM`: Marcadores temporales (kuri/-ta)

**Claude 3.5 Sonnet** manejÃ³ mejor estos casos complejos.
- **Velocidad y costo:** GPT-3.5 es mÃ¡s rÃ¡pido y econÃ³mico

### 6. ğŸ’¡ Recomendaciones para Mejorar el Sistema

**A corto plazo:**
1. âœ… **Usar Claude 3.5 Sonnet con Few-Shot** (mejor configuraciÃ³n actual)
2. Aumentar ejemplos few-shot con mÃ¡s casos del train set
3. Ajustar prompts para cada tipo de transformaciÃ³n especÃ­fica

**A mediano plazo:**
1. **Fine-tuning supervisado (SFT):** Entrenar modelo especÃ­fico con train set completo
2. Crear base de conocimiento con transformaciones reales (no solo gramÃ¡tica teÃ³rica)
3. Implementar ensemble de modelos (Claude + GPT combinados)

**A largo plazo:**
1. Expandir dataset con mÃ¡s ejemplos anotados
2. Entrenar modelo especializado en morfologÃ­a guaranÃ­
3. Crear sistema hÃ­brido: reglas lingÃ¼Ã­sticas + LLM

### 7. ğŸ“ Â¿RAG es Ãºtil para lenguas de bajo recurso?

**Respuesta basada en este estudio:** **No siempre.**

**Nuestros hallazgos:**
- âœ… RAG funciona cuando la base de conocimiento contiene **ejemplos prÃ¡cticos**
- âŒ RAG falla cuando solo contiene **teorÃ­a gramatical abstracta**
- âœ… Few-Shot directo (ejemplos en el prompt) superÃ³ a RAG en este caso
- ğŸ¯ **La calidad del corpus importa mÃ¡s que la tÃ©cnica RAG en sÃ­**

**Para lenguas de bajo recurso como el guaranÃ­:**
- Priorizar **ejemplos de transformaciones reales** sobre teorÃ­a
- Usar **few-shot learning** como lÃ­nea base fuerte
- RAG solo si se tiene corpus con transformaciones anotadas

**Importancia para idiomas indÃ­genas:**
- El guaranÃ­ tiene escasa representaciÃ³n en LLMs
- Few-shot demostrÃ³ ser mÃ¡s efectivo que RAG teÃ³rico
- MÃ©todo escalable: recopilar ejemplos > digitalizar gramÃ¡ticas

---

## ğŸ“ Archivos del Proyecto

### Resultados de la EvaluaciÃ³n
- `guarani_transformation_results.json` - Resultados detallados de todas las configuraciones
- `comparison_table.csv` - Tabla resumen con mÃ©tricas (Accuracy, BLEU)
- `rag_documents.json` - 1400+ chunks de gramÃ¡tica indexados
- `rag_metadata.json` - Metadatos del sistema RAG

### CÃ³digo Fuente
- `projectIA.ipynb` - Notebook completo con experimentos (**ejecutar en Google Colab**)
- `app.py` - AplicaciÃ³n Gradio para inferencia interactiva
- `requirements.txt` - Dependencias Python

### ConfiguraciÃ³n Docker
- `Dockerfile` - Contenedor Python 3.11
- `docker-compose.yml` - OrquestaciÃ³n con Gradio en puerto 7860
- `.env` - Variables de entorno (OPENROUTER_API_KEY)

---

## ğŸš€ CÃ³mo Ejecutar el Sistema

### OpciÃ³n 1: Google Colab (Recomendado para EvaluaciÃ³n)
1. Abre [`projectIA.ipynb`](https://colab.research.google.com/github/JuanAquino22/project_ia/blob/main/projectIA.ipynb) en Google Colab
2. Configura tu API key de OpenRouter en **Secrets**
3. Ejecuta todas las celdas secuencialmente
4. ObtendrÃ¡s: mÃ©tricas, grÃ¡ficos, y archivos descargables

### OpciÃ³n 2: Docker (Interfaz Gradio)
```bash
# Clonar repositorio
git clone https://github.com/JuanAquino22/project_ia.git
cd project_ia

# Configurar API key
echo "OPENROUTER_API_KEY=tu-key-aqui" > .env

# Construir y ejecutar
docker compose up --build

# Acceder a http://localhost:7860
```

# Acceder a http://localhost:7860
```

---

## ğŸ“Š Detalles TÃ©cnicos de la EvaluaciÃ³n

### Dataset AmericasNLP 2025
- **Train:** 800+ ejemplos (disponible para fine-tuning futuro)
- **Dev:** 100 ejemplos (usamos 10 para pruebas rÃ¡pidas)
- **Test:** Reservado para evaluaciÃ³n final oficial
- **Fuente:** [GitHub AmericasNLP](https://github.com/AmericasNLP/americasnlp2025)

### Tipos de Transformaciones Evaluadas
1. `TYPE:AFF` - Negativa â†’ Afirmativa (eliminar prefijo ndo- y sufijo -i)
2. `TYPE:NEG` - Afirmativa â†’ Negativa (agregar ndo-...-i)
3. `TENSE:FUT_SIM` - Agregar marcador futuro (-ta)
4. `TENSE:PAST` - Agregar marcador pasado (kuri)
5. `PERSON:1_PL_INC` - Cambiar a 1Âª plural inclusiva (Ã±ande)
6. `PERSON:1_PL_EXC` - Cambiar a 1Âª plural exclusiva (ore)
7. `PERSON:3` - Cambiar a 3Âª persona singular (ha'e)

### ConfiguraciÃ³n de HiperparÃ¡metros
- **Temperatura:** 0.2 (baja creatividad, salidas determinÃ­sticas)
- **Max tokens:** 150 por respuesta
- **Top-k RAG:** 2 documentos recuperados
- **Chunk size:** 650 caracteres
- **Chunk overlap:** 120 caracteres
- **Embedding:** Hash-based SHA-256 (384 dims)

---

## ğŸ”¬ Arquitectura del Sistema

### Pipeline de TransformaciÃ³n

```
OraciÃ³n Original â†’ Estrategia Seleccionada â†’ LLM â†’ OraciÃ³n Transformada
                         â†“
                   [Zero-Shot]
                   [Few-Shot]  
                   [Semantic RAG (FAISS)]
                   [Hybrid RAG (BM25+FAISS)]
```
---
### Componentes RAG
- **Base de conocimiento:** GramÃ¡tica GuaranÃ­ 2020 (200+ pÃ¡ginas)
- **Procesamiento:** 1400+ chunks extraÃ­dos con RecursiveCharacterTextSplitter
- **Embeddings:** SimpleHashEmbedding (SHA-256, sin modelos pesados)
- **Vector Store:** FAISS (bÃºsqueda por similitud)
- **BM25:** Ranking lexical con Okapi
- **Hybrid:** Ensemble BM25 (60%) + FAISS (40%)

---

## ğŸ“š Referencias y Recursos

- **Dataset oficial:** [AmericasNLP 2025 - Shared Task 2](https://github.com/AmericasNLP/americasnlp2025/tree/main/ST2_EducationalMaterials)
- **GramÃ¡tica utilizada:** Academia de la Lengua GuaranÃ­ (ALG), EdiciÃ³n 2020
- **Modelos LLM:** OpenRouter API ([openai/gpt-3.5-turbo](https://openrouter.ai/models/openai/gpt-3.5-turbo), [anthropic/claude-3.5-sonnet](https://openrouter.ai/models/anthropic/claude-3.5-sonnet))
- **Framework:** LangChain 0.3.0, FAISS, Gradio 3.50.2

---

## ğŸ‘¥ AutorÃ­a

**Proyecto realizado por:** Juan Aquino  
**Contexto:** Proyecto Final - Diplomado en Procesamiento de Lenguaje Natural e Inteligencia Artificial  
**InstituciÃ³n:** Facultad PolitÃ©cnica, Universidad Nacional de AsunciÃ³n (FPUNA)  
**Fecha:** Diciembre 2025

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **LangChain** - Framework para RAG
- **FAISS** - Vector store para bÃºsqueda de similitud
- **HuggingFace** - Modelo de embeddings multilingÃ¼e
- **OpenRouter** - API unificada para LLMs (GPT-3.5, Claude 3.5)
- **SacreBLEU** - MÃ©tricas de evaluaciÃ³n de texto
- **Pandas** - Procesamiento de datos


## ğŸ“š Referencias y Recursos

- [AmericasNLP 2025 - Educational Materials Task](https://turing.iimas.unam.mx/americasnlp/2025_st_2.html)
- [Dataset GitHub](https://github.com/AmericasNLP/americasnlp2025/tree/main/ST2_EducationalMaterials/data)
- GramÃ¡tica guaranÃ­ (Academia de la Lengua GuaranÃ­, EdiciÃ³n 2020)
- [OpenRouter API](https://openrouter.ai/)
- [LangChain Documentation](https://python.langchain.com/)

---

## âš ï¸ Notas Importantes

1. **API Key requerida:** ObtÃ©n una en [OpenRouter](https://openrouter.ai/)
2. **Colab recomendado:** El notebook estÃ¡ optimizado para Google Colab
3. **Resultados reproducibles:** Todos los experimentos son determinÃ­sticos (temp=0.2)
4. **Limitaciones:** EvaluaciÃ³n sobre 10 ejemplos (muestra del dev set)
5. **Archivo correcto:** Usar `projectIA.ipynb` (no versiones antiguas)

---


## ğŸ“ Contacto y Contribuciones

Para preguntas, sugerencias o colaboraciones:
- **GitHub:** [JuanAquino22](https://github.com/JuanAquino22)
- **Issues:** [Reportar problemas](https://github.com/JuanAquino22/project_ia/issues)
- **Pull Requests:** Â¡Contribuciones bienvenidas!


> ğŸ‡µğŸ‡¾ **Mba'Ã©ichapa!** Este proyecto demuestra que el guaranÃ­ puede beneficiarse de tÃ©cnicas modernas de NLP, pero requiere datos especÃ­ficos de calidad. Few-shot learning resultÃ³ mÃ¡s efectivo que RAG teÃ³rico, un hallazgo importante para lenguas de bajo recurso. Â¡Contribuciones y mejoras son bienvenidas!
