{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a0395c",
   "metadata": {},
   "source": [
    "# Chatbot RAG para Guaran√≠ - Idioma de Bajo Recursos\n",
    "\n",
    "Este notebook implementa un sistema de chatbot con RAG (Retrieval-Augmented Generation) para el idioma guaran√≠.\n",
    "\n",
    "## Objetivos:\n",
    "1. Comparar 2 modelos de LLM (GPT-3.5 Turbo vs Claude 3.5 Sonnet)\n",
    "2. Evaluar rendimiento con y sin RAG\n",
    "3. Comparar few-shot, zero-shot y RAG\n",
    "4. Evaluar si el idioma de bajo recursos se beneficia del RAG\n",
    "\n",
    "## Estructura:\n",
    "- Instalaci√≥n de dependencias\n",
    "- Carga de datos desde PDF de gram√°tica guaran√≠\n",
    "- Implementaci√≥n de RAG con FAISS\n",
    "- Configuraci√≥n de LLMs con OpenRouter\n",
    "- Evaluaci√≥n y comparaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6de1c3",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de librer√≠as necesarias\n",
    "!pip install -q langchain langchain-community\n",
    "!pip install -q chromadb\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q openai\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q transformers torch accelerate\n",
    "!pip install -q datasets\n",
    "!pip install -q faiss-cpu\n",
    "!pip install -q tiktoken\n",
    "!pip install -q pymupdf  # Para extracci√≥n de texto desde PDFs\n",
    "\n",
    "print(\"‚úì Dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550c1e7",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n e Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from getpass import getpass\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# LangChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Utilidades\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de API Keys (OpenRouter y HuggingFace)\n",
    "print(\"Configurando API Keys...\")\n",
    "print(\"Necesitas:\")\n",
    "print(\"1. OpenRouter API Key (para GPT-3.5 y Claude)\")\n",
    "print(\"2. HuggingFace Token (opcional, para modelos privados)\")\n",
    "print()\n",
    "\n",
    "OPENROUTER_API_KEY = getpass(\"Ingresa tu API Key de OpenRouter: \")\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "\n",
    "# HuggingFace token (opcional)\n",
    "HF_TOKEN = getpass(\"Ingresa tu HuggingFace Token (Enter para omitir): \")\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HUGGINGFACE_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "# Configuraci√≥n de dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\n‚úì Usando dispositivo: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435bc0b",
   "metadata": {},
   "source": [
    "## 3. Carga de Datos - PDF de Gram√°tica Guaran√≠\n",
    "\n",
    "En esta secci√≥n cargamos el PDF real de gram√°tica guaran√≠ y lo procesamos para crear chunks sem√°nticamente coherentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pdf_extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae texto de un archivo PDF usando PyMuPDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Ruta al archivo PDF\n",
    "        \n",
    "    Returns:\n",
    "        Texto extra√≠do del PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        \n",
    "        print(f\"Procesando PDF: {pdf_path}\")\n",
    "        print(f\"Total de p√°ginas: {len(doc)}\")\n",
    "        \n",
    "        for page_num, page in enumerate(doc, 1):\n",
    "            page_text = page.get_text()\n",
    "            text += f\"\\n--- P√°gina {page_num} ---\\n{page_text}\"\n",
    "            \n",
    "            if page_num % 10 == 0:\n",
    "                print(f\"  Procesadas {page_num} p√°ginas...\")\n",
    "        \n",
    "        doc.close()\n",
    "        print(f\"‚úì Extracci√≥n completada: {len(text)} caracteres\")\n",
    "        return text.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al procesar el PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Ruta al PDF (ajustar si es necesario)\n",
    "# En Colab, primero debes subir el archivo o montarlo desde Drive\n",
    "PDF_PATH = \"dataset/GramaticaGuarani.pdf\"\n",
    "\n",
    "# Si est√°s en Colab, descomenta estas l√≠neas para subir el archivo:\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# PDF_PATH = list(uploaded.keys())[0]\n",
    "\n",
    "# O monta Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# PDF_PATH = '/content/drive/MyDrive/path/to/GramaticaGuarani.pdf'\n",
    "\n",
    "# Extraer texto del PDF\n",
    "pdf_text = extract_text_from_pdf(PDF_PATH)\n",
    "\n",
    "# Mostrar muestra del texto extra√≠do\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MUESTRA DEL TEXTO EXTRA√çDO (primeros 500 caracteres):\")\n",
    "print(\"=\"*60)\n",
    "print(pdf_text[:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text_chunking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el texto en chunks sem√°nticamente coherentes\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Tama√±o de cada chunk en caracteres\n",
    "    chunk_overlap=200,  # Solapamiento entre chunks para mantener contexto\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Prioridad de separadores\n",
    ")\n",
    "\n",
    "# Crear chunks\n",
    "text_chunks = text_splitter.split_text(pdf_text)\n",
    "\n",
    "print(f\"‚úì Texto dividido en {len(text_chunks)} chunks\")\n",
    "print(f\"  Tama√±o promedio: {sum(len(chunk) for chunk in text_chunks) / len(text_chunks):.0f} caracteres\")\n",
    "print(f\"  Chunk m√°s peque√±o: {min(len(chunk) for chunk in text_chunks)} caracteres\")\n",
    "print(f\"  Chunk m√°s grande: {max(len(chunk) for chunk in text_chunks)} caracteres\")\n",
    "\n",
    "# Crear documentos de LangChain\n",
    "documents = []\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    documents.append(\n",
    "        Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"source\": \"GramaticaGuarani.pdf\",\n",
    "                \"chunk_id\": i\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úì Creados {len(documents)} documentos de LangChain\")\n",
    "\n",
    "# Mostrar ejemplo de un chunk\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EJEMPLO DE CHUNK #5:\")\n",
    "print(\"=\"*60)\n",
    "print(documents[5].page_content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eafc7e8",
   "metadata": {},
   "source": [
    "## 4. Implementaci√≥n del Sistema RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear embeddings multiling√ºes\n",
    "print(\"Cargando modelo de embeddings multiling√ºe...\")\n",
    "print(\"Modelo: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "print(\"Este modelo soporta 50+ idiomas, incluyendo espa√±ol y guaran√≠.\\n\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    model_kwargs={'device': device}\n",
    ")\n",
    "\n",
    "print(\"‚úì Modelo de embeddings cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48628c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vector store con FAISS\n",
    "print(\"Creando vector store con FAISS...\")\n",
    "print(f\"Procesando {len(documents)} documentos...\\n\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Guardar el vector store para uso posterior\n",
    "vectorstore.save_local(\"vectorstore_guarani\")\n",
    "\n",
    "print(\"‚úì Vector store creado y guardado en 'vectorstore_guarani/'\")\n",
    "print(\"  Este vector store se usar√° en la aplicaci√≥n Chainlit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar el retriever con una consulta de ejemplo\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Recuperar los 3 documentos m√°s relevantes\n",
    ")\n",
    "\n",
    "print(\"‚úì Retriever configurado\\n\")\n",
    "\n",
    "# Prueba de recuperaci√≥n\n",
    "test_query = \"¬øCu√°les son los pronombres personales en guaran√≠?\"\n",
    "print(f\"Consulta de prueba: {test_query}\\n\")\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(test_query)\n",
    "\n",
    "print(f\"Documentos recuperados: {len(relevant_docs)}\\n\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"--- Documento {i} ---\")\n",
    "    print(f\"Fuente: {doc.metadata['source']}\")\n",
    "    print(f\"Chunk ID: {doc.metadata['chunk_id']}\")\n",
    "    print(f\"Contenido (primeros 200 caracteres):\\n{doc.page_content[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068917e",
   "metadata": {},
   "source": [
    "## 5. Configuraci√≥n de LLMs con OpenRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class OpenRouterLLM:\n",
    "    \"\"\"Wrapper para usar OpenRouter con diferentes modelos\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, api_key: str):\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key\n",
    "        self.api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    \n",
    "    def __call__(self, prompt: str, **kwargs) -> str:\n",
    "        \"\"\"Genera respuesta del modelo\"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": kwargs.get(\"max_tokens\", 500),\n",
    "            \"temperature\": kwargs.get(\"temperature\", 0.7)\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            else:\n",
    "                error_msg = f\"Error {response.status_code}: {response.text}\"\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                return error_msg\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error de conexi√≥n: {str(e)}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return error_msg\n",
    "    \n",
    "    def generate(self, prompt: str, **kwargs) -> str:\n",
    "        \"\"\"Alias para compatibilidad\"\"\"\n",
    "        return self.__call__(prompt, **kwargs)\n",
    "\n",
    "# Configurar dos modelos diferentes para comparaci√≥n\n",
    "print(\"Configurando modelos LLM...\\n\")\n",
    "\n",
    "# Modelo 1: GPT-3.5 Turbo (m√°s r√°pido y econ√≥mico)\n",
    "model_1 = OpenRouterLLM(\n",
    "    model_name=\"openai/gpt-3.5-turbo\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n",
    "\n",
    "# Modelo 2: Claude Sonnet (m√°s potente)\n",
    "model_2 = OpenRouterLLM(\n",
    "    model_name=\"anthropic/claude-3.5-sonnet\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n",
    "\n",
    "print(\"‚úì Modelos configurados:\")\n",
    "print(\"  - Modelo 1: GPT-3.5 Turbo (OpenAI)\")\n",
    "print(\"  - Modelo 2: Claude 3.5 Sonnet (Anthropic)\")\n",
    "\n",
    "# Probar conexi√≥n con ambos modelos\n",
    "print(\"\\nProbando conexi√≥n con los modelos...\\n\")\n",
    "\n",
    "test_prompt = \"Di 'hola' en una palabra.\"\n",
    "print(f\"Prompt de prueba: {test_prompt}\\n\")\n",
    "\n",
    "print(\"Modelo 1 (GPT-3.5):\")\n",
    "response_1 = model_1.generate(test_prompt, max_tokens=50)\n",
    "print(f\"  Respuesta: {response_1}\\n\")\n",
    "\n",
    "print(\"Modelo 2 (Claude 3.5):\")\n",
    "response_2 = model_2.generate(test_prompt, max_tokens=50)\n",
    "print(f\"  Respuesta: {response_2}\\n\")\n",
    "\n",
    "if \"Error\" not in response_1 and \"Error\" not in response_2:\n",
    "    print(\"‚úì Ambos modelos funcionan correctamente\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Verifica tus API keys y conexi√≥n a internet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367d559",
   "metadata": {},
   "source": [
    "## 6. Implementaci√≥n de Diferentes Estrategias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuaraniChatbot:\n",
    "    \"\"\"Sistema de chatbot para guaran√≠ con diferentes estrategias\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, retriever=None):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "    \n",
    "    def zero_shot(self, question: str) -> str:\n",
    "        \"\"\"Estrategia Zero-Shot: sin ejemplos ni contexto adicional\"\"\"\n",
    "        prompt = f\"\"\"Eres un asistente experto en el idioma guaran√≠.\n",
    "        \n",
    "Pregunta: {question}\n",
    "\n",
    "Responde de manera clara y concisa.\"\"\"\n",
    "        \n",
    "        return self.llm.generate(prompt)\n",
    "    \n",
    "    def few_shot(self, question: str) -> str:\n",
    "        \"\"\"Estrategia Few-Shot: con ejemplos de referencia\"\"\"\n",
    "        prompt = f\"\"\"Eres un asistente experto en el idioma guaran√≠. Aqu√≠ hay algunos ejemplos:\n",
    "\n",
    "Ejemplo 1:\n",
    "Pregunta: ¬øC√≥mo se dice \"yo\" en guaran√≠?\n",
    "Respuesta: En guaran√≠, \"yo\" se dice \"Che\".\n",
    "\n",
    "Ejemplo 2:\n",
    "Pregunta: ¬øC√≥mo se dice \"hola\" en guaran√≠?\n",
    "Respuesta: En guaran√≠, una forma com√∫n de saludar es \"Mba'√©ichapa\", que significa \"¬øc√≥mo est√°s?\".\n",
    "\n",
    "Ejemplo 3:\n",
    "Pregunta: ¬øCu√°l es la estructura b√°sica de las oraciones en guaran√≠?\n",
    "Respuesta: El guaran√≠ usa una estructura SOV (Sujeto-Objeto-Verbo). Por ejemplo: \"Che tembi'u ajuka\" (Yo comida como).\n",
    "\n",
    "Ahora responde esta pregunta:\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    "        \n",
    "        return self.llm.generate(prompt)\n",
    "    \n",
    "    def rag(self, question: str) -> str:\n",
    "        \"\"\"Estrategia RAG: con recuperaci√≥n de documentos relevantes\"\"\"\n",
    "        if self.retriever is None:\n",
    "            return \"Error: Retriever no configurado\"\n",
    "        \n",
    "        # Recuperar documentos relevantes\n",
    "        relevant_docs = self.retriever.get_relevant_documents(question)\n",
    "        \n",
    "        # Construir contexto\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        prompt = f\"\"\"Eres un asistente experto en el idioma guaran√≠. Usa la siguiente informaci√≥n de referencia para responder la pregunta.\n",
    "\n",
    "CONTEXTO:\n",
    "{context}\n",
    "\n",
    "PREGUNTA: {question}\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Basa tu respuesta en la informaci√≥n del contexto proporcionado\n",
    "- Si la informaci√≥n no est√° en el contexto, ind√≠calo claramente\n",
    "- Responde de manera clara y educativa\n",
    "- Si es apropiado, incluye ejemplos en guaran√≠\n",
    "\n",
    "RESPUESTA:\"\"\"\n",
    "        \n",
    "        return self.llm.generate(prompt)\n",
    "\n",
    "print(\"‚úì Clase GuaraniChatbot implementada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d861a",
   "metadata": {},
   "source": [
    "## 7. Evaluaci√≥n y Comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4169ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntas de prueba m√°s espec√≠ficas basadas en gram√°tica guaran√≠\n",
    "test_questions = [\n",
    "    \"¬øCu√°les son los pronombres personales en guaran√≠?\",\n",
    "    \"¬øC√≥mo se dice 'nosotros' en guaran√≠ y cu√°l es la diferencia entre las formas inclusiva y exclusiva?\",\n",
    "    \"¬øCu√°l es el orden t√≠pico de las palabras en una oraci√≥n guaran√≠?\",\n",
    "    \"¬øC√≥mo se conjuga el verbo 'ir' en primera, segunda y tercera persona?\",\n",
    "    \"¬øCu√°les son los saludos m√°s comunes en guaran√≠?\",\n",
    "    \"¬øQu√© son los prefijos personales en guaran√≠ y c√≥mo se usan?\",\n",
    "    \"¬øC√≥mo se forma el plural en guaran√≠?\",\n",
    "    \"¬øCu√°les son las caracter√≠sticas principales de la fonolog√≠a del guaran√≠?\"\n",
    "]\n",
    "\n",
    "print(\"‚úì Preguntas de evaluaci√≥n preparadas:\")\n",
    "print(f\"  Total: {len(test_questions)} preguntas\\n\")\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"  {i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbec2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_model(model, model_name: str, retriever=None):\n",
    "    \"\"\"Eval√∫a un modelo con las tres estrategias\"\"\"\n",
    "    \n",
    "    chatbot = GuaraniChatbot(model, retriever)\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"strategies\": {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUANDO: {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for strategy_name in [\"zero_shot\", \"few_shot\", \"rag\"]:\n",
    "        print(f\"\\n--- Estrategia: {strategy_name.upper()} ---\\n\")\n",
    "        strategy_results = []\n",
    "        \n",
    "        for i, question in enumerate(test_questions, 1):\n",
    "            print(f\"Pregunta {i}/{len(test_questions)}: {question}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            if strategy_name == \"zero_shot\":\n",
    "                answer = chatbot.zero_shot(question)\n",
    "            elif strategy_name == \"few_shot\":\n",
    "                answer = chatbot.few_shot(question)\n",
    "            else:  # rag\n",
    "                answer = chatbot.rag(question)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"Respuesta ({elapsed_time:.2f}s): {answer[:150]}...\\n\")\n",
    "            \n",
    "            strategy_results.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"response_time\": elapsed_time\n",
    "            })\n",
    "            \n",
    "            # Peque√±a pausa para no saturar la API\n",
    "            time.sleep(1)\n",
    "        \n",
    "        results[\"strategies\"][strategy_name] = strategy_results\n",
    "        \n",
    "        avg_time = sum(r[\"response_time\"] for r in strategy_results) / len(strategy_results)\n",
    "        print(f\"\\n‚úì Estrategia {strategy_name.upper()} completada\")\n",
    "        print(f\"  Tiempo promedio de respuesta: {avg_time:.2f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úì Funci√≥n de evaluaci√≥n lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc422e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar Modelo 1 (GPT-3.5 Turbo)\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# INICIANDO EVALUACI√ìN DEL MODELO 1\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results_model_1 = evaluate_model(model_1, \"GPT-3.5 Turbo\", retriever)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì EVALUACI√ìN DEL MODELO 1 COMPLETADA\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar Modelo 2 (Claude 3.5 Sonnet)\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# INICIANDO EVALUACI√ìN DEL MODELO 2\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results_model_2 = evaluate_model(model_2, \"Claude 3.5 Sonnet\", retriever)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì EVALUACI√ìN DEL MODELO 2 COMPLETADA\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b594f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados\n",
    "import json\n",
    "\n",
    "all_results = {\n",
    "    \"model_1\": results_model_1,\n",
    "    \"model_2\": results_model_2,\n",
    "    \"metadata\": {\n",
    "        \"pdf_source\": \"GramaticaGuarani.pdf\",\n",
    "        \"total_questions\": len(test_questions),\n",
    "        \"embedding_model\": \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "        \"vector_store\": \"FAISS\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"evaluation_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úì Resultados guardados en 'evaluation_results.json'\")\n",
    "print(f\"  Tama√±o del archivo: {os.path.getsize('evaluation_results.json') / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc8ef1",
   "metadata": {},
   "source": [
    "## 8. An√°lisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebedf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_results(all_results):\n",
    "    \"\"\"Analiza y visualiza los resultados de la evaluaci√≥n\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AN√ÅLISIS DE RESULTADOS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # An√°lisis cuantitativo\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_key in [\"model_1\", \"model_2\"]:\n",
    "        model_data = all_results[model_key]\n",
    "        model_name = model_data[\"model\"]\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for strategy_name, strategy_results in model_data[\"strategies\"].items():\n",
    "            # Calcular m√©tricas\n",
    "            avg_length = sum(len(r[\"answer\"]) for r in strategy_results) / len(strategy_results)\n",
    "            avg_time = sum(r[\"response_time\"] for r in strategy_results) / len(strategy_results)\n",
    "            \n",
    "            print(f\"\\n  Estrategia: {strategy_name.upper()}\")\n",
    "            print(f\"    Total de respuestas: {len(strategy_results)}\")\n",
    "            print(f\"    Longitud promedio: {avg_length:.0f} caracteres\")\n",
    "            print(f\"    Tiempo promedio: {avg_time:.2f} segundos\")\n",
    "            \n",
    "            comparison_data.append({\n",
    "                \"Modelo\": model_name,\n",
    "                \"Estrategia\": strategy_name,\n",
    "                \"Longitud Promedio\": avg_length,\n",
    "                \"Tiempo Promedio\": avg_time\n",
    "            })\n",
    "    \n",
    "    # Crear DataFrame para visualizaci√≥n\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Gr√°fico 1: Longitud de respuestas\n",
    "    df_pivot = df.pivot(index=\"Estrategia\", columns=\"Modelo\", values=\"Longitud Promedio\")\n",
    "    df_pivot.plot(kind=\"bar\", ax=axes[0], rot=0)\n",
    "    axes[0].set_title(\"Longitud Promedio de Respuestas\", fontsize=14, fontweight=\"bold\")\n",
    "    axes[0].set_ylabel(\"Caracteres\")\n",
    "    axes[0].set_xlabel(\"Estrategia\")\n",
    "    axes[0].legend(title=\"Modelo\")\n",
    "    axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 2: Tiempo de respuesta\n",
    "    df_pivot_time = df.pivot(index=\"Estrategia\", columns=\"Modelo\", values=\"Tiempo Promedio\")\n",
    "    df_pivot_time.plot(kind=\"bar\", ax=axes[1], rot=0, color=[\"#FF6B6B\", \"#4ECDC4\"])\n",
    "    axes[1].set_title(\"Tiempo Promedio de Respuesta\", fontsize=14, fontweight=\"bold\")\n",
    "    axes[1].set_ylabel(\"Segundos\")\n",
    "    axes[1].set_xlabel(\"Estrategia\")\n",
    "    axes[1].legend(title=\"Modelo\")\n",
    "    axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONCLUSIONES Y PR√ìXIMOS PASOS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\"\"\n",
    "Para un an√°lisis completo, considera evaluar:\n",
    "\n",
    "1. PRECISI√ìN: ¬øLas respuestas son correctas seg√∫n la gram√°tica guaran√≠?\n",
    "   ‚Üí Revisar manualmente las respuestas compar√°ndolas con el PDF\n",
    "\n",
    "2. RELEVANCIA: ¬øLas respuestas abordan directamente la pregunta?\n",
    "   ‚Üí Verificar que las respuestas respondan lo que se pregunta\n",
    "\n",
    "3. COMPLETITUD: ¬øLas respuestas proporcionan informaci√≥n suficiente?\n",
    "   ‚Üí Evaluar si incluyen ejemplos y explicaciones adecuadas\n",
    "\n",
    "4. CONSISTENCIA: ¬øEl modelo es consistente en sus respuestas?\n",
    "   ‚Üí Comparar respuestas similares entre estrategias\n",
    "\n",
    "Compara especialmente:\n",
    "- Zero-shot vs Few-shot: ¬øLos ejemplos mejoran el rendimiento?\n",
    "- Few-shot vs RAG: ¬øEl contexto recuperado es m√°s √∫til que los ejemplos fijos?\n",
    "- Modelo 1 vs Modelo 2: ¬øQu√© modelo maneja mejor el idioma de bajo recursos?\n",
    "- RAG con PDF vs sin PDF: ¬øEl RAG realmente beneficia al guaran√≠?\n",
    "\n",
    "Gr√°fico guardado en: evaluation_comparison.png\n",
    "    \"\"\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar an√°lisis\n",
    "df_results = analyze_results(all_results)\n",
    "\n",
    "# Mostrar tabla de comparaci√≥n\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLA DE COMPARACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3418bb",
   "metadata": {},
   "source": [
    "## 9. Exportar Modelos y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar archivos necesarios para la aplicaci√≥n Chainlit\n",
    "print(\"Preparando archivos para descarga...\\n\")\n",
    "\n",
    "# Comprimir el vector store\n",
    "!zip -r vectorstore_guarani.zip vectorstore_guarani/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ARCHIVOS GENERADOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. vectorstore_guarani.zip\")\n",
    "print(\"   - Contiene el vector store FAISS con embeddings del PDF\")\n",
    "print(\"   - Descomprimir en el directorio del proyecto local\")\n",
    "print(\"\\n2. evaluation_results.json\")\n",
    "print(\"   - Resultados completos de la evaluaci√≥n\")\n",
    "print(\"   - Incluye respuestas de ambos modelos con las 3 estrategias\")\n",
    "print(\"\\n3. evaluation_comparison.png\")\n",
    "print(\"   - Gr√°ficos comparativos de rendimiento\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Si est√°s en Colab, descarga los archivos\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"\\nDescargando archivos...\")\n",
    "    print(\"1. Vector store (vectorstore_guarani.zip)\")\n",
    "    files.download('vectorstore_guarani.zip')\n",
    "    \n",
    "    print(\"2. Resultados de evaluaci√≥n (evaluation_results.json)\")\n",
    "    files.download('evaluation_results.json')\n",
    "    \n",
    "    print(\"3. Gr√°ficos de comparaci√≥n (evaluation_comparison.png)\")\n",
    "    files.download('evaluation_comparison.png')\n",
    "    \n",
    "    print(\"\\n‚úì Archivos descargados correctamente\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è No est√°s en Google Colab\")\n",
    "    print(\"Los archivos est√°n disponibles en el directorio actual\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PR√ìXIMOS PASOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Descargar los archivos generados\n",
    "2. Descomprimir vectorstore_guarani.zip en tu proyecto local\n",
    "3. Configurar el archivo .env con tu OPENROUTER_API_KEY\n",
    "4. Ejecutar la aplicaci√≥n Chainlit:\n",
    "   \n",
    "   cd /ruta/a/tu/proyecto\n",
    "   chainlit run app.py -w\n",
    "   \n",
    "5. Probar el chatbot con preguntas en guaran√≠\n",
    "6. Usar /rag on y /rag off para comparar modos\n",
    "\n",
    "¬°El sistema RAG para guaran√≠ est√° listo! üáµüáæ\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
